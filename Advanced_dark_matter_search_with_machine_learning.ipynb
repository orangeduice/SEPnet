{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "u5tqTS9zK_mf",
        "1n0SYHxbLdg_",
        "PByfguajLvvb",
        "9w_bGso9Ncyv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1FUSWDRDDflxrUrYBFPKHE50KrelBYO6N\" style=\"width:50%\" align=\"centre\">\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/University_of_Sussex_Logo.svg/1024px-University_of_Sussex_Logo.svg.png\" style=\"width:50%;\"  height=\"500\" width=\"500\" align=\"centre\">\n",
        "\n",
        "\n",
        "\n",
        "<!---weird that to put it in the middle I have to align it to the right-->"
      ],
      "metadata": {
        "id": "mWk_6sGEHNXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "X38dOWXVcMPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dark matter: Searching for the invisible\n",
        "#Workbook 3: Using machine learning\n",
        "\n"
      ],
      "metadata": {
        "id": "TmISK3D8flWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About ##"
      ],
      "metadata": {
        "id": "PoLLKi9vYnWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hello and welcome to the second part on finding dark matter from the ATLAS experiment. The ultimate goal of this part is to create a tool to optimise the inputs of event features to automatically determine the signal from the background, as you did manually in Workbook 2. We will create a type of machine learning model called a binary classifier. This will be trained to tell the difference between signal and background (thus being binary). Signal will be labelled with a **1** and background with a **0**.\n",
        "\n",
        "<br>\n",
        "HOW TO USE NOTEBOOK:\n",
        "\n",
        "* Run each code cell one at a time, if you leave the page replay every cell.\n",
        "* Fill in missing code in \"Do it yourself\" sections. \n",
        "* It is divided into sections that take around TIME to complete. \n",
        "* I recommend taking a break between each section to collect your thoughts. \n",
        "* There is a quiz at the end of each section to test your knowledge.\n",
        "\n"
      ],
      "metadata": {
        "id": "FLNiSyEDjGXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1: Intro##"
      ],
      "metadata": {
        "id": "Fd8JzN2jYALK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimental particle physics involves a lot of data analysis. The LHC produces up to 1 billion proton-proton collisions per second. This results in a tremendous amount of data (around one petabyte per day, or $10^{6}$ gigabytes) which must be understood to find the underlying physics. Machine learning really benefits from this large amount of data allowing for effective models to be trained. The efficiency and speed of machine learning methods also results in a massive decrease in computing time compared with manual methods (such as the cutting done in Workbook 2).\n",
        "At CERN, machine learning is used in many ways: for triggering, for event selection (what we shall be doing) and for particle and jet identification. See more on other uses [here](https://sparks.cern/ai-cern).\n",
        "\n"
      ],
      "metadata": {
        "id": "1GRtUdhGY3GA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This workbook will be using the python module scikit-learn to create the classifiers. This machine learning module is robust enough for us to make full use of machine learning models but is still readable and simple to initialise. If you wish to learn about more advanced machine learning libraries, I recommend PyTorch, TensorFlow, and especially Keras (all python modules).\n",
        "\n",
        "We will also need NumPy and pandas so we shall import these modules:\n"
      ],
      "metadata": {
        "id": "5nWBbNPXcirE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.axes as axes\n",
        "import ipywidgets as widgets #used to create interactive elements within the notebook\n",
        "\n",
        "plt.style.use('seaborn-deep') # plot styling"
      ],
      "metadata": {
        "id": "V_m0sDWKYH90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will also set a seed for this project, so the results are reproduceable:"
      ],
      "metadata": {
        "id": "1HT6pxbdcZ5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "#set seed value for all code\n",
        "seed_value = 420\n",
        "seed(seed_value)"
      ],
      "metadata": {
        "id": "v8szGz-dca9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2: What is machine learning? ##"
      ],
      "metadata": {
        "id": "hND7_sWPcftL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine learning (ML) is a type of **artificial intelligence**, which is the computing field of developing computer programs/algorithms that perform tasks that typically require human intelligence, such as problem-solving. This workbook will focus on supervised learning. This is when we train a machine learning model with example data of what we are looking for.\n",
        "\n",
        "**Example:** Let's say we want to teach a computer to recognise a dog in a picture. We will train the computer on lots of images of animals while telling the program what images correspond to dogs. This will teach the computer to correctly recognise images of dogs.\n"
      ],
      "metadata": {
        "id": "UFt15aD-mDOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1: General principles ###"
      ],
      "metadata": {
        "id": "oU_AdvBNnY4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine learning models are computer algorithms that are trained to achieve specific goals without being programmed with explicit instructions on how to achieve them; they are not *programmed* but *trained*.\n",
        "\n",
        "There are three main tasks of machine learning:\n",
        "1.   **Regression:** The input is a set of multi-feature data points, and the output is a real number or a sequence of real numbers (e.g. inputs could be the features of a house and the output could be a predicted house price, [link](https://medium.com/codex/house-price-prediction-with-machine-learning-in-python-cf9df744f7ff)). \n",
        "2.   **Classification:** The input is a set of multi-feature data points and the output is an integer which represents different classes (e.g. based on what is contained within an email, a machine learning model could sort between mail and spam, [link](https://towardsdatascience.com/email-spam-detection-1-2-b0e06a5c0472)).\n",
        "3.   **Generation:** The input is noise and the output is something desirable (E.g. Input is a random seed and the output is generated images of people that don’t exist, [link]( https://www.boredpanda.com/ai-image-generation-fake-faces-people-nvidia/?utm_source=google&utm_medium=organic&utm_campaign=organic)).\n",
        "\n",
        "\n",
        "In this notebook we shall be training a **classifier**.\n",
        "*   We will have <font color='#819468'>**objects**</font> which we are interested in.\n",
        "\n",
        "*   These objects need to be <font color='#688194'>**classified**</font> into a set number of groups.\n",
        "\n",
        "*   To do this the <font color='#946881'>**features**</font> of the objects are used.\n",
        "\n"
      ],
      "metadata": {
        "id": "KdiV81JaS38z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.1: Pre-processing and notation ####"
      ],
      "metadata": {
        "id": "irq9heXGCbsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before training our machine learning models we must prepare the data so the computer can make sense of it. We define a data set called $X$ which holds all the objects (with $x$ as a single object) and a $y$ data set which will hold all the labels that correspond to the objects (the $X$ data set).\n",
        "\n",
        "As well as doing this we will split the data up into two parts: training data and testing data. The purpose of these data sets is evident in their names. The classifier is trained on the training data then tested on the testing data - this is discussed further in Section 3.1 but the key point is that the testing data is new unseen data for the classifier to be tested on after training.\n"
      ],
      "metadata": {
        "id": "kKrZStrlCr-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.2: How does classification work? ####"
      ],
      "metadata": {
        "id": "21d7qGycrLWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets take a step back from particle physics and consider different objects, lets say spherical fruit (e.g. apple, orange, tomato, etc.). We can identify the type of fruit using two features: colour and average radius. So we define an object as\n",
        "\n",
        "$x\\left (c, r  \\right )$.\n",
        "\n",
        "We want to create an algorithm that can classify these <font color='#819468'>objects</font> into two groups: lemons and everything else (e.g. grapes, oranges, apples, etc.). Lets say we have two <font color='#819468'>objects</font>:\n",
        " \n",
        "$x_{1}\\left (yellow, 2cm  \\right ) = \\text{a lemon}$, \n",
        "\n",
        "$x_{2}\\left (green, 8cm  \\right ) =  \\text{NOT a lemon (a watermelon)}$.\n",
        "\n",
        "We can plot these two points in a 2D graph with colour and radius as the dimensions:\n",
        "![MLd1_f](https://lh4.googleusercontent.com/-6YTfe0Nt1YOBBCb3-AreVNNjjyQeiSOlO0FZv_d8fPJC-VblzWN017DgcseX_DY8zE=w2400)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H0dVJJoMrYM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These points are the training data. The algorithm is explicitly told that these are, or are not, lemons, soo it is using them to learn how to identify a lemon. Let's add more <font color='#819468'>objects</font> to train the algorithm:\n",
        "\n",
        "![MLd2_f](https://lh5.googleusercontent.com/bMdPJpENrYD1Zgs3zxv_7HtloOMb93eM8bS23THq-8jSFs655MEf_9qGoEF1UT9WXR0=w2400)"
      ],
      "metadata": {
        "id": "r6E8sZccdnuk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These <font color='#819468'>objects</font> make up the training data, The machine learning model uses them to \n",
        "find the boundaries of this plot to <font color='#688194'>classify</font> the two groups:\n",
        "\n",
        "![MLd3_f](https://lh3.googleusercontent.com/7YDZ5amhf3SvfRafzZN8GvKAKIkGTVF_9rHhOJRKJLjmsXB4PzikgC9_rReG2LpNtDc=w2400)"
      ],
      "metadata": {
        "id": "8mf3RNseduQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then from these boundaries, the model can predict if a new <font color='#819468'>object</font> is a lemon or not a lemon by looking at where it is on the plot. So, let's introduce a new fruit that has not been seen. This is considered the testing data as it is unlabelled and was not seen by the machine learning model during training:\n",
        "\n",
        "![MLd4_f](https://lh5.googleusercontent.com/C-H8k2ctNTziBRKi4I3sUZbVJRbXwB3fE2bbHZWiNc_Fq2UDxDjGUquk5yMB35BLiuU=w2400)"
      ],
      "metadata": {
        "id": "wPdl9f4TfAPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The machine learning algorithm doesn’t know what it is \n",
        "supposed to be, and has to use what it has learnt from the training data to \n",
        "guess if it is an orange or not. In this case, it would guess that the new fruit is not a lemon."
      ],
      "metadata": {
        "id": "q_yD_YXEimLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obviously these two features are not enough to identify every type of fruit correctly. So, let's introduce more! Let's say we now have $N$ <font color='#946881'>features</font> (new features such as volume or colour brightness). Now our graph will be in $N$ dimensions. This is not plottable but the same logic as for 2-D is upheld:\n",
        "the machine learning model will find the part of this $N$-dimensional space (hyperspace) which belongs to lemons. It recognises complex pattens in the data.\n",
        "\n",
        "This is how machine learning models are trained to classify objects.\n"
      ],
      "metadata": {
        "id": "bv7nx4hMioJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.3: What is training? ####"
      ],
      "metadata": {
        "id": "-p4Ije04KalX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have been talking about training a lot, but what does it entail? In machine learning, we teach computer algorithms and test them to see how good they are at doing their job. We then give feedback to the algorithm which it uses to become more accurate. This process iterates until the algorithm can do its task to a set standard. Over time, the algorithm changes its logic to produce accurate results.\n"
      ],
      "metadata": {
        "id": "0kFb-IbkRENW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2: Our application ###"
      ],
      "metadata": {
        "id": "BlI1V_8gi5pG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So now our $N$ dimensions are the features of the collision events (the same properties we were cutting in Workbook 2). We will train our classifier to recognise the complex patterns in the data to identify the signal events from the background ones."
      ],
      "metadata": {
        "id": "AozAArgKyua8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have objects:\n",
        "<font color='#819468'>\n",
        "*   **Collision events** from the Monte Carlo simulation (**1.2 million events**)\n",
        "</font>\n",
        "\n",
        "With the goal:\n",
        "<font color='#688194'>\n",
        "*   Classify **signal** from **background** (labelled as **1 or 0**)</font>\n",
        "\n",
        "To do this, we will use the features of the objects (**N = 7**):\n",
        "<font color='#946881'>\n",
        "*   **Leading lepton's transverse momentum** \n",
        "*   **Sub-leading lepton's transverse momentum** \n",
        "*   **Dilepton invariant mass** ($m_{ll}$)\n",
        "*   **Missing transverse energy** ($E_{Tmiss}$)\n",
        "*   **Angle between $E_{Tmiss}$ and net momentum of the dilepton** ($\\Delta \\phi$)\n",
        "*   **Fractional transverse momentum difference** \n",
        "*   **Missing transverse energy over total momentum** $E_{Tmiss}/H_T$\n",
        "</font>\n"
      ],
      "metadata": {
        "id": "2Zwt_62SjEyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the machine learning model to recognize the signal from background we shall train it on all the processes:"
      ],
      "metadata": {
        "id": "2xa89seooc67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table>\n",
        "<thead>\n",
        "<tr><th>Non-resonant lepton pair production</th><th>Z+ boson jets</th><th>W and Z boson production</th><th>Double Z boson production</th><th>Dark matter production</th></tr>\n",
        "</thead>\n",
        "</table>"
      ],
      "metadata": {
        "id": "j0LW7akNqXGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets made an array to hold the names of the processes\n",
        "processes = ['nonres',\n",
        "              'Zjets',\n",
        "              'WZ',\n",
        "              'ZZ',\n",
        "              'DM_300']"
      ],
      "metadata": {
        "id": "1gdIzt-mqlvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As before we consider every process except dark matter production (DM 300) to be the background. Now let's get load the data we need to do the analysis:"
      ],
      "metadata": {
        "id": "nRlYhGo9mkvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Option to use local file if you download the notebook locally, will run better with slower internet speeds\n",
        "files_local = True\n",
        "\n",
        "#This dictionary will hold all the event data for each process \n",
        "All_processes = {} \n",
        "\n",
        "#We now loop through all the processes and read the data from either local files or from the web address\n",
        "index = 0  #This index is for identifying the process, will increment while looping\n",
        "\n",
        "for process in processes: \n",
        "    if files_local:\n",
        "        All_processes[process] = pd.read_csv('/content/drive/MyDrive/Data/'+process+'.csv')\n",
        "    else:\n",
        "        All_processes[process] = pd.read_csv('https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/csv/DM_ML_notebook/'+process+'.csv') # read data files\n",
        "    \n",
        "    #We will add a process ID to the data set to help with identification\n",
        "    All_processes[process][\"processID\"] = index\n",
        "    index = index + 1"
      ],
      "metadata": {
        "id": "axvBbM-5qYIO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "71ef9400-2c7f-409f-aba8-6993e079c975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d179cdca60d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprocess\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfiles_local\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mAll_processes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Data/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mAll_processes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/csv/DM_ML_notebook/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# read data files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Data/nonres.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have loaded the data let's go over the two types of classifiers we will be training."
      ],
      "metadata": {
        "id": "m-ZqFx4IDdnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3: Random forest ###"
      ],
      "metadata": {
        "id": "6UZ9bp3JsPCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first method we shall be going over is the **random forest**. This is a black box, ensemble learning method using **decision trees**. Now, there is a lot to unpack in that sentence but that is the technical description. This method works by creating a set number of [decision trees](https://www.youtube.com/watch?v=_L39rN6gz7Y) of a set depth - these are themselves machine learning models - then using them all in unison to make classifications.\n",
        "\n",
        "Decision trees are a structure of repeated binary cuts on individual variables (exactly like you did manually in Workbook 2) in a flowchart like layout. Cuts are made at decision nodes. Leaf nodes are where the cuts end and a classification is made. When this happens is determined by a criterion that measures the quality of a cut. Examples include gini, entropy and log loss (read more about this in Section 2.3.1). The diagram below shows such a tree:\n"
      ],
      "metadata": {
        "id": "IFqIuUz8vmBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Dtree](https://lh3.googleusercontent.com/93Lh9CaVLKpS2EYyOa-a5T5FZpRR2uMWqGiHeST_zbk3jA_JKynhxEi7eFhziW_9kOY=w2400)\n"
      ],
      "metadata": {
        "id": "_7buN8M0vrdz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is optimised at each node to give the best separation of signal and background. They are very susceptible to overtraining (more on this later), but random forests overcome this.\n",
        "\n",
        "Each tree is trained using a random sample of $X$ with replacement (this is called **bootstrapping**) and a random selection of features to use for each tree (each tree can specialise). Each tree is then trained independently. Any new data point is passed through each tree to get different predictions. These predictions are combined to get a final one, this is called **aggregation**, and follows the same logic as \"wisdom of the crowd\".\n",
        "\n",
        "The diagram below shows the layout of a random forest made up of decision trees:\n",
        "![RF_DIA](https://lh3.googleusercontent.com/FzS39r5yR5K0daoJVKSj7eztT4btXsg2Owp5LRaXHrsPBxi_Qmhl_1adoINzrVtan9Y=w2400)\n",
        "\n",
        "\n",
        "Random forests have several **advantages**:\n",
        "* Overfitting is reduced due to ensemble learning, improving their accuracy;\n",
        "* Works well with both discrete and continuous variables;\n",
        "* Normally uneffected by outliers and missing values, which they can handle automatically;\n",
        "* The algorithm is very stable;\n",
        "* It is less affected by noise;\n",
        "* The feature importance can be identified.\n",
        "\n",
        "Yet, they also come with some **disadvantages**:\n",
        "* They require a large amount computational power resulting in longer training periods;\n",
        "* They have added complexity when lots of decision trees are trained.\n",
        "\n"
      ],
      "metadata": {
        "id": "YGijZGwvwUYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3.1: Advanced section: Gini, entropy and log loss"
      ],
      "metadata": {
        "id": "x-ihDfMuK547"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a nutshell, each of the three functions measure the quality of a cut in a decision tree, but in distinctly different ways. However, the exact mathematical formulations for each of them can be quite involved, even for regular users of machine learning. In the following, the interested reader may find rough descriptions, but you are encouraged to do any further reading yourself if you want more information.\n",
        "\n",
        "* **Gini impurity** measures the probability that data is mislabelled by the node as the incorrect class. If this probability is **0**, the node is pure (all data contained at the node are of the same class) and the decision tree will no longer split at that node. Under this method, the aim is for splits to be made which minimise gini impurity of nodes. More information may also be found [here](https://en.wikipedia.org/wiki/Decision_tree_learning). \n",
        "\n",
        "* **Entropy** calculates the disorder of features at a node. Similarly to gini impurity, the aim is for this to be minimised when a feature is used to split the data. Although it seems that gini and entropy are basically the same, more information can be found [here](https://quantdare.com/decision-trees-gini-vs-entropy/) which further outlines the subtle differences.\n",
        "\n",
        "* **Log loss** is a metric which is also sought to be minimised. The log loss is usually $-1 \\times log(L)$ where $L$ is something called a likelihood function. Liklihood functions provide a way to assess how well an observed outcome matches an expected one. In the context of decision trees, this is an assessment of how well the binary classification of a node corresponds to the actual makeup of data at that node. Further information can be found [here](https://towardsdatascience.com/intuition-behind-log-loss-score-4e0c9979680a) and [here](https://www.kaggle.com/code/dansbecker/what-is-log-loss/notebook).\n",
        "\n",
        "Further information on the three methods can also be found [here](https://scikit-learn.org/stable/modules/tree.html#tree-mathematical-formulation) and by a look at the variety of sources on the web. Yet, again, none of this information is needed to complete this workbook!!!"
      ],
      "metadata": {
        "id": "dQo-oKSxMVUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4: Neural network ###"
      ],
      "metadata": {
        "id": "4SWhmbU29KGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second method is the **neural network**, a mathematical function inspired by the biological neural networks of animal brains. It is made up of nodes/artificial neurons connected by weights. These weights signify the importance of each connection to make the correct prediction. Each neuron acts as a function by having a value dependent on those weights. \n",
        "\n",
        " Neural networks are constructed of layers of nodes:\n",
        "\n",
        "*   Input layer\n",
        "*   Hidden layers\n",
        "*   Output layer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HZVqXv_A9QlO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input layer has a node for each dimension of the input. Here, these are the event features. Hidden layers exists which can be a varying size (the size is set before training and is called a hyperparameter) and there is an output layer made up of nodes which correspond to each classification group. \n",
        "\n",
        "The values of the input nodes correspond to the features of the objects to be identified and the output node vaules will correspond to what the object will be classified as.\n",
        "\n",
        "The diagram below shows the layout of a nodes and weights that make up a neural network:\n",
        "![NN_DIA](https://lh5.googleusercontent.com/L-bJ7gYuPDcO6lMqKg1LXx4inag-SR8afwMqnyfOZSKCKn3NBeUY7dEvS9MGar_hHnc=w2400)\n",
        "\n",
        "Again, as well as the advantages of machine learning as whole, neural networks have several other **advantages**:\n",
        "* Continuous Learning: a neural network can be trained continuously to improve its performance over time (it does not need to be retrained when training on more data);\n",
        "* They have a parallel processing capability;\n",
        "* There is an error tolerance due to the complexity of neurons;\n",
        "* Neural netweorks store the information of the data they are trained on\n",
        "* They are flexible.\n",
        "\n",
        "Yet, they also comes with some **disadvantages**:\n",
        "* Due to their parallel processing, they can be hardware dependant;\n",
        "* The algorithms can become very complex when used for specified tasks; \n",
        "* They have a black box nature: this means that the logic in which the neural network makes decisions is not understandable by humans due to its complexity;\n",
        "* The results are only approximations;\n",
        "* They are very dependent on the data: the whole nature of a neural network is dependent on the data it is trained on so erroneous data will, in turn, affect it. \n"
      ],
      "metadata": {
        "id": "zQMyVPB5bwZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try experimenting with different layer sizes to see how the neural network is constructed. Run the hidden cell below this, then in the next cell set what parameters you want."
      ],
      "metadata": {
        "id": "6Gg6_jzcqzj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def NeuralNetworkPlot(input_node_size,hidden_layer_sizes,output_node_size):\n",
        "    \n",
        "    fig = plt.gcf()\n",
        "    ax = fig.gca()\n",
        "    \n",
        "    scale = 0.2\n",
        "    \n",
        "    layer_widths = [input_node_size]\n",
        "    \n",
        "    for y in range(0,hidden_layer_sizes[1]):\n",
        "        layer_widths.append(hidden_layer_sizes[0])\n",
        "    layer_widths.append(output_node_size)\n",
        "    \n",
        "    max_width = max(layer_widths)\n",
        "    \n",
        "    buffer =  ( max_width - np.array(layer_widths) )/2\n",
        "    #print(buffer)\n",
        "    node_locations = []\n",
        "    \n",
        "    for i,o in zip(layer_widths,buffer):\n",
        "        node_locations.append(np.linspace(0, i-1,i)+o)\n",
        "    \n",
        "    to_be_plotted = 0\n",
        "    \n",
        "    \n",
        "    \n",
        "    for i in range(0,len(node_locations)):\n",
        "        layer = node_locations[i]\n",
        "        if i == len(node_locations) -1:\n",
        "            break\n",
        "        next_layer = node_locations[i+1]\n",
        "        for o in range(0,len(layer)):\n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "            node = layer[o]\n",
        "            #print(node)\n",
        "            #print(\"=======\",i,i+1)\n",
        "            original = np.full(len(next_layer),node)\n",
        "            \n",
        "            #print(original) \n",
        "            \n",
        "            next_ = next_layer\n",
        "            #print(next_layer)\n",
        "            temp = np.c_[original,next_layer]\n",
        "            \n",
        "            \n",
        "            #print(\"=======\")\n",
        "            \n",
        "            for u,p in zip(original,next_layer):\n",
        "                line = plt.Line2D([(i*scale),(i+1)*scale],[u*scale,p*scale],color = \"grey\", lw = 0.3)\n",
        "                plt.gca().add_line(line) \n",
        "            \n",
        "            # for u in temp:\n",
        "            #     #print(i,i+1)\n",
        "            #     #print(u[0],u[1])\n",
        "                \n",
        "            #     line = plt.Line2D([i,i+1],[u[0],u[1]])\n",
        "                \n",
        "            #      \n",
        "    for i in range(0,len(node_locations)):\n",
        "        layer = node_locations[i]\n",
        "        if i == 0:\n",
        "            colour = 'green'\n",
        "        elif i == len(node_locations)-1:\n",
        "            colour = 'red'\n",
        "        else:\n",
        "            colour = 'black'\n",
        "        plt.scatter(np.full(len(layer),i)*scale,layer*scale,zorder=10,color = colour,s=20/scale)\n",
        "            \n",
        "            \n",
        "            # circle1 = plt.Circle((i,layer[o]),0.1,color = 'r')\n",
        "    \n",
        "            # ax.add_patch(circle1)        \n",
        "    \n",
        "    \n",
        "    plt.xlim([-1*scale, (i+1)*scale])\n",
        "    plt.ylim([-1*scale, (max_width+3)*scale])\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.text((0-1)*scale,(max_width)*scale,\"Input layer\",color = 'green',fontsize = 20)\n",
        "    plt.text((0+1)*scale,(max_width)*scale,\"Hidden layers, \"+str(hidden_layer_sizes),fontsize = 20)\n",
        "    plt.text((len(layer_widths)-1)*scale,(max_width)*scale,\"Output Layer\",color='red',fontsize = 20)\n",
        "    \n",
        "    plt.text((0.75)*scale,(max_width+2)*scale,\"Neural network diagram\",fontsize = 30)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    fig.set_size_inches((max_width+3)*scale*10,(i+1)*scale*10)\n",
        "    #plt.savefig('myfigure_100.png', dpi=300)\n",
        "    plt.show()\n",
        "    #plt.rcParams[\"figure.figsize\"] = ((i+1),(max_width+1)*2)   \n",
        "    \n",
        "    \n",
        "            \n",
        "            \n",
        "            \n",
        "           \n",
        "            \n",
        "    \n",
        "    \n",
        "    \n",
        "    #print(np.array(node_locations))    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#print(np.c_[np.array([1,1,1,1,1]),np.array([0,1,2,3,4])]) "
      ],
      "metadata": {
        "id": "757Z-UsprVZ-",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Try out different sizes of layers\n",
        "NeuralNetworkPlot(6,(3,4),1) \n",
        "#                 ^input nodes\n",
        "#                     ^hidden nodes\n",
        "#                         ^output nodes"
      ],
      "metadata": {
        "id": "Vp3s55QarXpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2 quiz ###"
      ],
      "metadata": {
        "id": "JXGfFtWIPuv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"Which of the following is NOT a 'black box' machine learning model?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Random forest',0),('Neural network',0),('Decision tree',1)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "id": "2aB5_IBKjDVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"In random forest machine learning models, how can I reduce overfitting?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Increase each decision tree\\'s maximum depth',0),('Increase the number of decision trees in the forest',1),('Decrease the number of variables being used',0)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yobrQJJ8j_7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"I want to design a machine learning model which is\"+ \n",
        "      \" capable of sorting 10,000 \\n images a day based on their\"+\n",
        "      \" average colour, average brightness, resolution in \\n DPI \"+\n",
        "      \"(dots per inch) and the number of red pixels contained \"+\n",
        "      \"within them. My \\n model would need to split the data into \"+\n",
        "      \"seven categories. How many dimensions \\n would I need to \"+\n",
        "      \"represent the data hyperspace?\")\n",
        "out = widgets.Dropdown(options=[('',0),('2',0),('4',1),('7',0),('10000',0)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-WtJX0h8kcod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"You decide to train a neural network on your system which uses an Nvidia \\n\"+\n",
        "      \"graphics card. When you decide to switch to an identical system, except that \\n\"+\n",
        "      \"it uses an Intel graphics card, you find that the neural network no longer works \\n\"+\n",
        "      \"as expected. Why?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Neural networks can be hardware dependent',1),('You can\\'t use neural networks on Intel graphics cards',0),('You made a programming mistake',0)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "id": "mah7BUpNn_NC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3: Application ##"
      ],
      "metadata": {
        "id": "xApG9bCEM6T0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now use these concepts to create two binary classifiers using a random forest and a neural network. We will train them using the same Monte Carlo data used in Workbook 2 of this workbook series."
      ],
      "metadata": {
        "id": "UD79ri8uNJly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1: Pre-processing ###"
      ],
      "metadata": {
        "id": "AxWQjDH-NPQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As said in Section 2.2, we shall be using seven properties of  the collision events as the features for the machine learning models:\n",
        "\n",
        "<table>\n",
        "<thead>\n",
        "<tr><th>Leading lepton's transverse momentum</th><th>Sub-leading lepton's transverse momentum</th><th>$m_{ll}$</th><th>$E_{Tmiss}$</th><th>$\\Delta{}\\phi{}$</th><th>Fractional transverse momentum difference</th><th>$E_{Tmiss}$/$H_T$</th></tr>\n",
        "</thead>\n",
        "</table>\n"
      ],
      "metadata": {
        "id": "axd5-wEO8RyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identify the properties we want\n",
        "ML_inputs = ['totalWeight',\n",
        "             'lead_lep_pt', \n",
        "             'sublead_lep_pt', \n",
        "             'mll',\n",
        "             'ETmiss', \n",
        "             'dphi_pTll_ETmiss', \n",
        "             'fractional_pT_difference',\n",
        "             'ETmiss_over_HT',\n",
        "             'processID'] #copy over process ID but will not be used in ML training"
      ],
      "metadata": {
        "id": "5tD2nqnR8mkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We shall start the pre-processing by creating a dictionary of data to be used by the machine learning models. We will start by copying over all the event data but only while disregarding any event properties we don't care about. **Note :** You will also notice that \"totalWeight\" is also included in the dictionary. It is not because this is directly used as a feature in machine learning models. Rather, this is to account for the [selection effects](https://docs.google.com/document/d/1B_bzcKqTnBBZ-0K02aurW9o8FgfWlmEO-PxuP-f4ves/edit) of Monte Carlo generated data. Please keep an eye on where \"totalWeight\" makes appearances throughout this workbook, since this is used to properly scale our analysis and evaluation of the trained models.  "
      ],
      "metadata": {
        "id": "IMaBfNzb9PGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This dictionary will hold all the event properties we will feed into the ML model\n",
        "ML_data={}\n",
        "\n",
        "#Again looping through all the processes \n",
        "for process in processes:\n",
        "    ML_data[process] = All_processes[process][ML_inputs].copy()\n",
        "    #This line makes entrys in ML_data by copying all the ML inputs from All_processes\n",
        "    #see pandas indexing for more infomation https://pandas.pydata.org/docs/user_guide/indexing.html"
      ],
      "metadata": {
        "id": "isaCR1yJ-bYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As said earlier before training our machine learning models, we must prepare the data so the computer can make sense of it. We start doing this by creating two data sets:"
      ],
      "metadata": {
        "id": "raiHJtyKNXLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **$X$ data set**: this will hold all the input data for the machine learning model. This is done by selecting all the events from every process, then filtering the properties/features we want and combining them into a larger dataset. Note that the order of this data set is important.\n",
        "\n"
      ],
      "metadata": {
        "id": "1F-5BcdUOT-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We shall be using scikit-learn to split the data into the training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "#This function will split the data and suffle it, ratio of test to train can be changed here as well\n",
        "\n",
        "def splitter(X, y, test_size = 0.33, random_state = seed_value):\n",
        "  X_train_WID, X_test_WID, y_train, y_test = train_test_split(X, y, \n",
        "                                                              test_size = 0.33, \n",
        "                                                              random_state = seed_value)\n",
        "\n",
        "\n",
        "  # Save the process IDs of the events from the train and test data sets \n",
        "  X_train_ID = X_train_WID[:,-1]\n",
        "  X_test_ID = X_test_WID[:,-1]\n",
        "  # Take the process IDs off so they dont interfere\n",
        "  X_train_t = np.delete(X_train_WID,-1,1)\n",
        "  X_test_t = np.delete(X_test_WID,-1,1)\n",
        "\n",
        "\n",
        "  # Save the weights of the events from the train and test data sets\n",
        "  X_train_W = X_train_t[:,0]\n",
        "  X_test_W = X_test_t[:,0]\n",
        "  # take the weights off so they dont interfere\n",
        "  X_train = np.delete(X_train_t,0,1)\n",
        "  X_test = np.delete(X_test_t,0,1)\n",
        "\n",
        "  return X_train, X_train_W, y_train, X_test, X_test_W, y_test"
      ],
      "metadata": {
        "id": "yeIJpXvE-Tk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We will now create the X data set ===========================================\n",
        "#Looping through each process and appending each to a numpy array that will hold \n",
        "#all the event data\n",
        "all_ML_data = []\n",
        "for process in processes:\n",
        "    all_ML_data.append(ML_data[process])\n",
        "\n",
        "X = np.concatenate(all_ML_data)\n",
        "#============================================================================="
      ],
      "metadata": {
        "id": "q-62syA78tFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **$y$ dataset**: this is a list of 1's and 0's corresponding to signal and background that lines up with the $X$ data set."
      ],
      "metadata": {
        "id": "XUSZ0qZq8qU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We will now create the y data set: ==========================================\n",
        "#Again looping through each process process and appending a set of either 1 or 0 \n",
        "#depending if the process is background or not\n",
        "all_ML_classes = []\n",
        "\n",
        "for process in processes: \n",
        "    process_data_size = ML_data[process].shape[0] #set number of events in process\n",
        "    if 'DM' in process:\n",
        "        all_ML_classes.append(np.ones(process_data_size)) #1's for signal\n",
        "    else:\n",
        "        all_ML_classes.append(np.zeros(process_data_size)) #0's for background\n",
        "\n",
        "y = np.concatenate(all_ML_classes)\n",
        "#============================================================================="
      ],
      "metadata": {
        "id": "AAIanlZ98w6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The diagram below shows the two data sets we have now created if each process has four data entries (obviously this is not actually the case):\n",
        "![data_diagram](https://lh3.googleusercontent.com/Q-oatcdBOqaxC4Oh7eIThv9VZCbySHq_xuUZjIrg46css0NTVqWUTvRw6BsHf8K8-f4=w2400)"
      ],
      "metadata": {
        "id": "xNQlEyD0taa_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In machine learning training, it is important to have training and testing sets of data. \n",
        "\n",
        "> Isn’t it the dream of every student to get very similar exam questions to ones they practiced with? It is easy to score well when you are familiarized with the problems being asked. To guarantee a fair test, teachers make sure to split their bank of questions into a training and a testing set. As such, students will have plenty to practice but still receive unseen questions on the test. The same applies to machine learning!\n",
        "\n",
        "If the machine learning model is trained on all the data, then tested on all the data the results will not give us any understanding on the effectiveness of the model as it is biased to test it on what it was trained with.\n",
        "\n",
        "To program this split of training and testing data, we shall simply feed in the **$X$** and **$y$** data sets into a function from the scikit-learn module that does it for us. Here, we will reserve a third of the data for testing with the remainder for training.\n"
      ],
      "metadata": {
        "id": "lnMHYZTR_3L1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We shall be using scikit-learn to split the data into the training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "#This function will split the data and suffle it, ratio of test to train can be changed here as well\n",
        "X_train_WID, X_test_WID, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = seed_value)\n",
        "\n",
        "\n",
        "# Save the process IDs of the events from the train and test data sets \n",
        "X_train_ID = X_train_WID[:,-1]\n",
        "X_test_ID = X_test_WID[:,-1]\n",
        "# Take the process IDs off so they dont interfere\n",
        "X_train_t = np.delete(X_train_WID,-1,1)\n",
        "X_test_t = np.delete(X_test_WID,-1,1)\n",
        "\n",
        "\n",
        "# Save the weights of the events from the train and test data sets\n",
        "X_train_W = X_train_t[:,0]\n",
        "X_test_W = X_test_t[:,0]\n",
        "# take the weights off so they dont interfere\n",
        "X_train = np.delete(X_train_t,0,1)\n",
        "X_test = np.delete(X_test_t,0,1)"
      ],
      "metadata": {
        "id": "Uhdvt3z__3on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v4mB5KAv_Ok4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IENW8hKr5FCu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These data sets must now be normalised. This is important for the neural network model to converge. This is done again using scikit-learn. \n",
        "The importance of normalisation isn't obvious, but is needed. You may also think of it akin to standardisation, because it brings the mean average of data inputs close to some standard value (e.g. 0). This helps to speed up the optimisation of a neural network and reduce 'issues' along the way. These issues are intimately related to gradient descent (see Section 4.2.1) and the way in which a neural network is trained. For now, an analogy may be useful:\n",
        "\n",
        "> Let's say you are trained to work in a factory screwing various nuts and bolts into holes in pieces of furniture. If you are trained to work with nuts and bolts which are all of a similar size and weight, your musucle memory will help you to perform this task quicker; but if you are trained to work with nuts and bolts which vary irratically in this respect, it can be harder for you to optimise your way of working to easily complete your task. Thus, the factory decide to use a standard range of parts for you to use and you are happier.\n",
        "\n",
        "By standardising/normalising the inputs in machine learning, the machinary behind neural networks can behave in a more \"predictable\" way, thus improving the outcome.\n"
      ],
      "metadata": {
        "id": "Z2kv7XDeCCk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<html>\n",
        "<details>\n",
        "<summary style=\"color:orange; font-weight: bold;\">For more information</summary>\n",
        "please have a look [here](https://towardsdatascience.com/why-data-should-be-normalized-before-training-a-neural-network-c626b7f66c7d), [here](https://arxiv.org/pdf/1805.11604.pdf) and [here](https://medium.com/techspace-usict/normalization-techniques-in-deep-neural-networks-9121bf100d8)."
      ],
      "metadata": {
        "id": "_aUILvLwbOEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the needed function from scikit-learn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#call the scaler opject then fit it to the X_train data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "#Now scale/normalise both of the X data sets by transforming them with the scaler we just created\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "tlubBcBgCKNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have the needed data to train our machine learning models."
      ],
      "metadata": {
        "id": "vfsSK2gYCW9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 3 quiz ###"
      ],
      "metadata": {
        "id": "JYYYnX3LP3FF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"Why must there be independent training and testing datasets when developing machine learning models?\")\n",
        "out = widgets.Dropdown(options=[('',0),('To assess model accuracy',0),('To assess overfitting or underfitting',0),('Both',1)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lp8-WDV9pNzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"In the above code, why is the \\\"processID\\\" deleted from the data\"+\n",
        "      \"before the data are used in training or testing?\")\n",
        "out = widgets.Dropdown(options=[('',0),('We do not want the \"processID\" to be treated as an input variable',1),('We simply want to cut down on memory usage',0),('The MC data don\\'t have processIDs to use',0)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2IxlqmOspOEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"I decide to train a machine learning model to classify objects as \\\"round\\\" or \\\"not round\\\".\\n\"+\n",
        "      \"I choose to use two class labels: 0 and 1. If my objective is to select objects which are \\n\"+\n",
        "      \"\\\"round\\\" and to discard those which are \\\"not round\\\", does it matter which label I use for \\n\"+\n",
        "      \"which category?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Yes',0),('No',1),('It depends',0)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "B3w2rkVQpOqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4: Model training ##"
      ],
      "metadata": {
        "id": "gIjeN1y5Culv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now that we understand and have prepared the data and features that we are using, we will now go through the process of training our machine learning models. As a reminder, training will involve teaching the algorithms with data which it will attempt to categorise between DM signal and background. As the data is labelled to indicate the \"true\" signal and background, this is **supervised learning** in which the labels provide feedback for how well the machine learning models are doing.  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gw1rWFdjG_5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1: Random forest (RF) ###"
      ],
      "metadata": {
        "id": "W_TIRlJKCyNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We shall start by training the random forest classifier. This is completed on a tree-by-tree basis. Each decision tree training is completed using the \"classification and regression tree\" (CART) algorithm, then ensemble learning is used to make final predictions from all the separate tree predictions."
      ],
      "metadata": {
        "id": "02GrIl-IHvEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1.2: Training the RF #### "
      ],
      "metadata": {
        "id": "sLO3m2uEKwsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We shall be training the random forest using scikit-learn. This module will give us the options to change the model’s hyperparameters before training:\n",
        "\n",
        "*   **Criterion** : The function used to measure the quality of a split; it determines if a node is now a leaf node. \n",
        "*   **Bootstrap** : Bootstrap or not? (See Section 2.3)\n",
        "*   **Max depth** : The maximum depth of every decision tree.\n",
        "*   **Max features** : Number of features to consider for each decision tree. \n",
        "*   **No. of estimators** : The number of decision trees in the forest.\n",
        "*   **Random state** : Controls both the randomness of the bootstrapping of the samples used when building trees, and the sampling of the features to consider when looking for the best split at each node."
      ],
      "metadata": {
        "id": "prfqsVzqLpNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train the random forest classifer with these hyperparameters:"
      ],
      "metadata": {
        "id": "CvWkleXyW4kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the random forest Class\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# initialize the classifer with the wanted hyperparameters\n",
        "RF_clf = RandomForestClassifier(criterion = 'gini', \n",
        "                                bootstrap = True,       \n",
        "                                max_depth = 4,  \n",
        "                                max_features = \"sqrt\",           \n",
        "                                n_estimators = 500,         \n",
        "                                random_state = seed_value, \n",
        "                                verbose = 1, #\n",
        "                                n_jobs = -1) #\n",
        "\n",
        "# train the classifer (use normalised X data to help converge)\n",
        "RF_clf.fit(X_train_scaled,y_train) "
      ],
      "metadata": {
        "id": "L7ngzRqQLh5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2: Neural network (NN) ###"
      ],
      "metadata": {
        "id": "blP2MrdtGRrT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will be training the neural network classifier. To begin, the neural network is randomly seeded, then something called the loss function is calculated by comparing predictions (on the training data) to the expected values. Next, we perform something called gradient descent to minimise this loss function which is done through backpropagation - adjustment of weights for each neuron, layer-by-layer, to improve the prediction. You may read more about the training in the next advanced section however, it is not necessary to continue the notebook (and will not be in the quiz).\n"
      ],
      "metadata": {
        "id": "qcf2f1vEYaEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2.1: Advanced section: NN training####"
      ],
      "metadata": {
        "id": "Bd0W0i3kGkst"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insert YouTube videos\n",
        "\n",
        "\"Gradient descent is an iterative operation which seeks to find local minima or maxima of a function\" may be one such way of defining it, but this may be a lot to unpack. Instead, it may be more convenient to use an analogy: gradient descent is analogous to the whole process of hiking down the mountain and it is related to the steepness of the loss function. In more technical terms, it is the iterative process of calculating the current value of the loss function (scouting) and then altering the inner parameters of the NN by a step down in the loss function (stepping). The NN repeats this process through multiple iterations, each time decreasing the step size (field of view decreases) until it reaches a model optimized for successfully classifying signal and background events (a city is reached).\n",
        "\n",
        "In the animation below, the black dot represents the position of a neural network as it descends along the gradient by a definite step size. Just like you might see in a topographic map, the gradient of the loss function is colour-coded in a mesh where red are the peaks and blue are the valleys. Note how the descent slows down as the gradient flattens. Did your hiking adventure look like that?\n",
        "\n",
        "![Gradient Descent Diagram](https://drive.google.com/uc?export=view&id=1YeUNA9oDVNyPxX_Re1lIx1Z3ZIBm24Nv)\n",
        "\n",
        "You may recall that the normalisation is linked with gradient descent. In more precise language, normalisation/standardisation is done to make the gradient descent optimisation work faster. If data is not normalised, there is the chance that gradient descent is less likely to converge to a solution for a loss function (e.g. you are hiking along a \"mountain\" which looks rather flat for miles and miles around and are unable to easily see a path to the lowest point; or you are hiking over such a small mound of a mountain - say an anthill - that your stride is great enough that you step right over the mound without seeing it!!). "
      ],
      "metadata": {
        "id": "-bNyMD-tGnAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2.2: Training the NN #### "
      ],
      "metadata": {
        "id": "iW6mXh3xGn7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We shall also be training the neural network using scikit-learn. Again, we have the option to change the model’s hyperparameters before training:\n",
        "\n",
        "*   **Solver** : The solver used in weight optimization (see Section 4.2.1).\n",
        "*   **Activation** : Activation function for the hidden layer  (see Section 4.2.1).\n",
        "*   **Hidden layer sizes** : Set the number of hidden layers and the number of nodes in each one.\n",
        "*   **Shuffle** : Whether to shuffle samples in each iteration or not.\n",
        "*   **Random state** : Determines random number generation for seeding weights and bias initialisation.\n",
        "\n"
      ],
      "metadata": {
        "id": "CzzNwo8XGyPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train the neural network classifer with these hyperparameters:"
      ],
      "metadata": {
        "id": "cAZYcx8MSsLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the multi-layer perceptron Class\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "# initialize the classifer with the wanted hyperparameters\n",
        "NN_clf = MLPClassifier(solver = 'adam',\n",
        "                        activation ='relu',\n",
        "                        hidden_layer_sizes = (100,5),\n",
        "                        shuffle = True,\n",
        "                        random_state = seed_value,\n",
        "                       \n",
        "                        verbose=1)\n",
        "\n",
        "# train the classifer (use normalised X data to help converge)\n",
        "NN_clf.fit(X_train_scaled, y_train) "
      ],
      "metadata": {
        "id": "-8XjmYvFHCRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3: Prediction sneak peek ###"
      ],
      "metadata": {
        "id": "sBnYtd9hNtfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have trained the classifiers, lets briefly experiment with prediction. First of all, we will pick a random event object from the test data set:"
      ],
      "metadata": {
        "id": "xO-Dh1vTODSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import randint\n",
        "#get a random number to sample random object \n",
        "rand_num = randint(0,X_test.shape[0])\n",
        "\n",
        "#Take a random object from x test\n",
        "event_object = X_test[rand_num]\n",
        "scaled_event_object = X_test_scaled[rand_num]"
      ],
      "metadata": {
        "id": "62d2k9S9Ama1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's find out if this event is signal or background:"
      ],
      "metadata": {
        "id": "fSSeFw6mA0YS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Is this event signal or background? \n",
        "event_object_label =  y_test[rand_num]\n",
        "\n",
        "#Print features of object and label\n",
        "print(event_object,event_object_label)\n"
      ],
      "metadata": {
        "id": "4Sb4zZNbA9-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So now we know what this event is actually classified as, let’s see if the classifiers correctly predict what this event is (signal or background). We can do this using the **predict($X$)** method in scikit-learn, this returns the predicted class of an input sample.\n"
      ],
      "metadata": {
        "id": "vuo0IksBA0ep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#make both into 2d arrays so .predict works\n",
        "event_object = np.array([event_object])\n",
        "scaled_event_object = np.array([scaled_event_object])\n",
        "\n",
        "print(event_object)\n",
        "\n",
        "#Perdict using both classifers\n",
        "RF_Perdiction = RF_clf.predict(event_object)\n",
        "NN_Perdiction = NN_clf.predict(scaled_event_object)\n",
        "\n",
        "#print predictions\n",
        "print(\"Random forest prediction:\",RF_Perdiction)\n",
        "print(\"Neural network prediction:\",NN_Perdiction)"
      ],
      "metadata": {
        "id": "5xFkuNLbDRwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This class prediction is found from the prediction probabilities of being signal and of being background. We can get these probabilities by using the **predict_log_proba($X$)** method in scikit-learn which acts on the classifier:"
      ],
      "metadata": {
        "id": "pITTXkDrDVmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the probability of predictions\n",
        "RF_Perdiction_prob =  RF_clf.predict_proba(event_object)\n",
        "NN_Perdiction_prob = NN_clf.predict_proba(scaled_event_object)\n",
        "\n",
        "#print probability of predictions\n",
        "print(\"Random forest prediction probability:\",RF_Perdiction_prob)\n",
        "print(\"Neural network prediction probability:\",NN_Perdiction_prob)\n"
      ],
      "metadata": {
        "id": "S4qplhUEDqNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This method returns two probabilities in an array with index 0 holding the background probability and index 1 holding the signal probability. We are most interested in the probability of an event being signal. These probabilities are much more use to us then just the class label as we can study the range of probabilities to understand how our classifiers are working.\n",
        "\n",
        "In the next section we will look at these predicted probabilities (also considered the *response* of the machine learning model) for the whole test data set $X$. We will see that the full responses produce distributions which can be analysed, like what was done in Workbook 2.\n"
      ],
      "metadata": {
        "id": "S422twK5IEoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 4 quiz ###"
      ],
      "metadata": {
        "id": "ssBQUK8BP6Gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"When training a neural network, how does it optimise itself?\")\n",
        "out = widgets.Dropdown(options=[('',0),('By maximising a \"gain\" function',0),\n",
        "                                ('By stabilising an output',0),\n",
        "                                ('By minimising a \"loss\" function',1)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tHbsOXjSrS0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"Which of the following is NOT a hyperparameter of a neural network?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Hidden layer sizes',0),\n",
        "                                ('Verbose',1),\n",
        "                                ('Activation',0)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "P883x5-xrTfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"In training the random forest, which of the following hyperparameters was responsible \\n\"+\n",
        "      \"for each decision tree being trained on a random sample of the training data with replacement?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Random state',0),\n",
        "                                ('Bootstrap',1),\n",
        "                                ('No. of estimators',0)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xjOLW9e_rTuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5: Prediction and model evaluation ##"
      ],
      "metadata": {
        "id": "BQC1qr0LOezA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have trained the classifiers, we can use them to predict if an event is background or signal.\n",
        "\n",
        "We must also evaluate these models to understand how well they are working and give us the chance to optimise the machine learning models' responses. We will perfect the classifiers using the Monte Carlo data, then we will be able to use it in practice with real experimental data. \n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "YHtRi47c1HSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1: Model analysis ###"
      ],
      "metadata": {
        "id": "9lWcwFXK6eRn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis methods include:\n",
        "*   Plotting ML model response for signal and background\n",
        "*   ROC curve\n",
        "*   Overfitting check\n",
        "*   KS test\n",
        "\n",
        "This section will go through these methods, and you will be given a chance to optimise the classifiers for the best and most accurate prediction.\n"
      ],
      "metadata": {
        "id": "zukQpRtJ62WQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.1.1: Model response ####"
      ],
      "metadata": {
        "id": "EUgoBYvT4Iz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the response of the classifiers using the test data we see how the model is responding to the signal and background differently. As was said in Section 4.3, we will look at the predictions for the whole $X$ test data set. When we do this, we will see a distribution of responses over the whole data set. The goal for the coming sections will be to optimise this response to clearly see two distributions in this data - one for signal and one for background. This indicates new physics.\n",
        "\n",
        "How would we plot this? If we take the $x$-axis of a plot to be the predicted probability that an object is signal, then we plotted all the objects in a sample as two separate histograms (one for signal labelled objects and one for background labelled) on the same axis, we can see the distributions. We can do this as we know beforehand which events are background and signal (the $X$ test set corresponds with $y$ test labels). Note this would not be possible with real, non-Monte Carlo data as it is unlabelled. Let’s consider a perfect classifier, the plot would look like:\n",
        "\n"
      ],
      "metadata": {
        "id": "cCI4Z1Pi7BDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![out_1](https://lh6.googleusercontent.com/TiZwRuPDGvuDb6jZ2H2ymbyplcCBr1DCs-f45ufKFroxFpsxUUqXRymtXPJ-ezYyddU=w2400)"
      ],
      "metadata": {
        "id": "crt8T3CsK3Hy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In reality the classifier, is not perfect, but a strong separation of signal from the background could look like this:\n",
        "![output_2](https://lh5.googleusercontent.com/Vfn64iGQDJVxQvFFQEkol-DGgCGUQGLyWIfk7GLcOdTShAFTO8xef1ZkTgOLpwp9wGs=w2400)"
      ],
      "metadata": {
        "id": "BGBnjY9oOqtg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A real example of this from the ATLAS experiment can be seen below. This shows two clear distributions for the total background (blue) and the Higgs signal (dotted red). NOTE: the horizontal axis here is NN output not the prediction, but generally these can be considered as the same (just with a different horizontal axis range). The Higgs signal considered here is a rather specific process which (crucially) involves a Higgs boson.\n",
        "\n",
        "![atlasNNoutput](https://lh5.googleusercontent.com/9J_6RG1mf8jIg5Uy2J4zVTmvTXqZE-0jHz4KO0OV9jne3Rl93HbSdUEpNg9srK74yrc=w2400)\n",
        "\n",
        "The two distributions clearly show different trends in how the neural network responds, suggesting it is a useful NN for isolating a signal. This neural network was developed in work which sought to find evidence of a Higgs boson by isolating the signal for this specific Higgs process. This graph shows that a cut (more in Section 5.2) on the NN output between $0.0$ and $0.5$ could strongly select for the Higgs process. We will be looking to use our ML models in a similar way to find dark matter!!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AVD5JgKrPTEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let’s plot the response of our classifiers. We will plot two histograms - orange for signal and blue for background. While the $y$-axis of response plots can be expressed using a variety of units, the plots we will be creating will be histograms for the **frequency** with which the classifier outputs some signal probability between $0$ and $1$. We shall write a function to plot the output of any classifier for the $X$ data we give it:"
      ],
      "metadata": {
        "id": "w2Xehz9YPa7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BINS = 16\n",
        "\n",
        "def plot_response(clf,Title,sig,sig_weights,bkg,bkg_weights,n_bins,Log):\n",
        "    \"\"\"\n",
        "    This function plots the response of a classifer on signal and background \n",
        "    Monte Carlo events\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    fig : TYPE\n",
        "        DESCRIPTION.\n",
        "    clf : TYPE\n",
        "        DESCRIPTION.\n",
        "    Title : TYPE\n",
        "        DESCRIPTION.\n",
        "    sig : TYPE\n",
        "        DESCRIPTION.\n",
        "    sig_weights : TYPE\n",
        "        DESCRIPTION.\n",
        "    bkg : TYPE\n",
        "        DESCRIPTION.\n",
        "    bkg_weights : TYPE\n",
        "        DESCRIPTION.\n",
        "    n_bins : TYPE\n",
        "        DESCRIPTION.\n",
        "    index : TYPE\n",
        "        DESCRIPTION.\n",
        "    xAxis : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    # Get response (in form of probabilities) of signal and background \n",
        "    sig_prob = clf.predict_proba(sig)[:, 1]\n",
        "    bkg_prob = clf.predict_proba(bkg)[:, 1]\n",
        "    # find min and max for plot\n",
        "    d_min = min(sig_prob.min(), bkg_prob.min())\n",
        "    d_max = max(sig_prob.max(), bkg_prob.max())\n",
        "    \n",
        "    \n",
        "    \n",
        "    # plot background response (make orange and translucent)\n",
        "    plt.hist(bkg_prob,\n",
        "             bins = n_bins,\n",
        "             range = (d_min,d_max),\n",
        "             color = 'tab:blue', \n",
        "             label = 'bkg test',\n",
        "             alpha = 0.4, \n",
        "             density = False,\n",
        "             weights = bkg_weights,\n",
        "             log = Log,\n",
        "             histtype=\"stepfilled\",\n",
        "             edgecolor='tab:blue',\n",
        "             linewidth=5)\n",
        "    \n",
        "    \n",
        "    # plot signal response (make blue and translucent)\n",
        "    plt.hist(sig_prob,\n",
        "             bins = n_bins,\n",
        "             range = (d_min,d_max),\n",
        "             color = 'tab:orange', \n",
        "             label = 'sig test', \n",
        "             alpha = 0.4, \n",
        "             density = False,\n",
        "             weights = sig_weights,\n",
        "             log = Log,\n",
        "             histtype = \"stepfilled\",\n",
        "             edgecolor ='tab:orange',\n",
        "             linewidth = 5)\n",
        "\n",
        "    # Set up plot\n",
        "    plt.title(Title)\n",
        "    plt.xlabel(\"Response (0 = background, 1 = signal)\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.legend()\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(12, 6)\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "    \n",
        "    return"
      ],
      "metadata": {
        "id": "8aEvEjPLIeSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To call this function properly, we must sort the $X$ test and training data into background and signal data sets; further, we must sort the $X$ data's **weights** too (remember that since the data here are Monte Carlo, we MUST use the weights to **rescale** the data so that we can plot the frequencies as if they were real data):"
      ],
      "metadata": {
        "id": "UWWax7AMIrOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort signal data into new arrays one for X vaules and one for the weights\n",
        "sig_test     =  X_test_scaled[y_test >= 0.5]\n",
        "sig_test_W   =       X_test_W[y_test >= 0.5]\n",
        "sig_train    =  X_train_scaled[y_train >= 0.5]\n",
        "sig_train_W  =       X_train_W[y_train >= 0.5]\n",
        "# Sort background data into new arrays one for X vaules and one for the weights\n",
        "bkg_test     =  X_test_scaled[y_test <= 0.5]\n",
        "bkg_test_W   =       X_test_W[y_test <= 0.5]\n",
        "bkg_train    =  X_train_scaled[y_train <= 0.5]\n",
        "bkg_train_W  =       X_train_W[y_train <= 0.5]"
      ],
      "metadata": {
        "id": "ef3j8ecaI_vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's call the function and plot the response of the classifers, first for the random forest:"
      ],
      "metadata": {
        "id": "LpJrB5aIY0-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_response(RF_clf, \n",
        "              \"Random forest response\", \n",
        "              \n",
        "              sig_test, \n",
        "              sig_test_W,\n",
        "              bkg_test,\n",
        "              bkg_test_W,\n",
        "              \n",
        "              BINS,\n",
        "              False)"
      ],
      "metadata": {
        "id": "1-tlQWnxKZIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is hard to see the signal as dark matter is such a rare process. So let's set the $y$-axis to logarithmic scaling:"
      ],
      "metadata": {
        "id": "uIGsN_m-KapO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_response(RF_clf, \n",
        "              \"Random forest response\", \n",
        "              \n",
        "              sig_test, \n",
        "              sig_test_W,\n",
        "              bkg_test,\n",
        "              bkg_test_W,\n",
        "              \n",
        "              BINS,\n",
        "              True)"
      ],
      "metadata": {
        "id": "uifv0t-rWhmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That is much better - we can see the distributions. Now let's do the same for the neural network:"
      ],
      "metadata": {
        "id": "ysNe-BBOWkyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_response(NN_clf, \n",
        "              \"Neural network response\", \n",
        "              \n",
        "              sig_test, \n",
        "              sig_test_W,\n",
        "              bkg_test,\n",
        "              bkg_test_W, \n",
        "              \n",
        "              BINS,\n",
        "              True)"
      ],
      "metadata": {
        "id": "z7KkdWSCWskz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the start of Section 5.1.1, we outlined some general, if optimisitic, response plots which showed a good degree of separation between some background and some signal. In contrast, the plots which we have produced show a less distinct separation between DM signal and background in the MC data. This doesn't mean that the neural network or random forest are not doing anything to classify the data. Rather it is simply because we are trying to find a very tricky DM signal (which remember is similar enough to our background such that a cut-based optimisation is not enough). \n",
        "\n",
        "Instead, we see that the background and signal responses follow different responses;\n",
        "\n",
        "* For the random forest, the response is rather uniform for the signal data, whereas the background response is peaks towards $0.00$ and decreases for higher probabilities;\n",
        "\n",
        "* For the neural network, the signal response is less uniform than for the neural network but is spread out over a larger range than the random forest; the background response peaks towards $0.00$ and decreases rapidly.\n",
        "\n",
        "From our intermediate results, you may be able to make a guess as to which machine learning model produces a better separation between background and signal - neural network or random forest?"
      ],
      "metadata": {
        "id": "wiJj-3YtY9nY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  5.1.2: ROC curve ####\n"
      ],
      "metadata": {
        "id": "hh3FVV6r4Zvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand how well the machine learning model is working, we can look at the ROC curve. To do this, let's first introduce some new metrics: <font color='green'>TP</font> (number of true positives), <font color='red'>FN</font> (number of false negatives), <font color='red'>FP</font> (number false positives) and <font color='green'>TN</font> (number of true negatives). These are defined as the following:\n",
        "\n",
        "*   TP: Signal events correctly identified as signal events;\n",
        "*   FN: Signal events incorrectly identified as background events;\n",
        "*   FP: Background events incorrectly identified as signal events;\n",
        "*   TN: Background events correctly identified as background events.\n",
        "\n",
        "As you may have realised in this case, a background event is considered negative while a signal event is considered positive. \n",
        "\n",
        "The box in the image below shows the definition of these metrics. The columns divide objects predicted as signal (left) and background (right) while the rows divide objects that are actually signal (top) and background (bottom).\n",
        "\n",
        "From these metrics we can construct two values to describe the effectiveness of our classifiers: true positive rate and false positive rate. Below these values are explained:"
      ],
      "metadata": {
        "id": "0doLc_Pe7Zle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![ROC](https://lh4.googleusercontent.com/dRQIT12SO5RR4paENExHGImZuJXMV49OR6Ezk8NtmclBLDnmJUBdLmlnq9fIr-d45eg=w2400)"
      ],
      "metadata": {
        "id": "EKtj2_5T9IYJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have these two values we can optimize them for the best classification. Let’s think back to Section 5.1.1 where we plotted the response of our models in the form of two histograms on the same plot to show the distributions:\n",
        "![NN_response](https://lh3.googleusercontent.com/p8MOLHdqZSGFAaBsmpxTjwXm-BwRK4lZtlY_SPSO4rK_5JgCISCJlTuuJ81aGHhWQDA=w2400)"
      ],
      "metadata": {
        "id": "AVrt5U8R9nbw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider a vertical line on this plot that represents a threshold. Everything to the right of that vertical line is now classified as a signal event, and everything to the left a background event. We can move this line to the left or right in turn changing the threshold. Doing this changes the TP, FN, FP and TN numbers and thus in turn changes the TPR and FPR. If we change this threshold from 0 to 1 (going from left to right) we can plot TPR and FPR as they change. This plot is called the 'receiver operating characteristic' (ROC) curve. With TPR as the $y$-axis and FPR as the $x$-axis, the plot below shows (as well as other lines) an example of a neural networks ROC curve (blue line):"
      ],
      "metadata": {
        "id": "ypZcqiLmBq-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![rocCurve](https://lh6.googleusercontent.com/1hC1foz56Jr5pLrluF0sRyaOKR5Nr0Oj0mgd-8ls2OMOHCESigFL7DcK9paD888yScQ=w2400)"
      ],
      "metadata": {
        "id": "G1W3WDHVAGSW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rrxWbYjS6jxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   **Perfect classifier** : A perfect classifier will 100% correctly classify signal from background;\n",
        "*   **Random classifier** : A random classifier will randomly classify signal form background;\n",
        "*   **NN classifier** : An example of a decent classifier.\n",
        "\n",
        "The goal is to minimise FPR and maximise TPR, or in other words, to get the curve as far as possible to the top left hand corner.\n"
      ],
      "metadata": {
        "id": "P2BNA47EFclH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let’s plot the ROC curves for both our classifiers. Luckily for us, scikit-learn has a built-in function that does this for us. The **roc_curve** function takes in the $y$ test data, the array of thresholds (classifier response probabilities) and outputs corresponding FPRs and TPRs:"
      ],
      "metadata": {
        "id": "hFlitwJ3HDC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the needed modules to analyse the classifers\n",
        "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
        "\n",
        "# get predictions for X test data\n",
        "y_pred_RF = RF_clf.predict(X_test_scaled)\n",
        "y_pred_NN = NN_clf.predict(X_test_scaled)\n"
      ],
      "metadata": {
        "id": "GedHURpNIF9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s now define a function to plot the ROC curve for both a classifer and a random classifier:"
      ],
      "metadata": {
        "id": "K7s9GSuxIGUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_roc(clf, \n",
        "             X, \n",
        "             X_weight, \n",
        "             y,\n",
        "             Title):\n",
        "    \"\"\"\n",
        "    This function calculates the ROC curve for a given classifer then plots it.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    # Get the prediction of the classifer\n",
        "    y_prob = clf.predict_proba(X)[:,1]\n",
        "    \n",
        "    # Use the scikit-learn function to calulate the FPR and TPR vaules corresponding\n",
        "    # to the therssholds. The line after that finds the area under the ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y ,y_prob, sample_weight = X_weight)\n",
        "    # roc_auc = roc_auc_score(y ,y_prob, sample_weight = X_weight,labels=[0,1])\n",
        "    roc_auc = 1\n",
        "    \n",
        "    # set up the plot\n",
        "    plt.figure()\n",
        "    plt.plot(fpr,tpr,color='tab:orange', lw=2, label='ROC Curve (area = %0.2f)'%roc_auc)\n",
        "    plt.plot([1,0],[1,0], color='tab:blue', lw=2, linestyle='--', label='Random classifier')\n",
        "    plt.xlim([0.0,1.0])\n",
        "    plt.ylim([0.0,1.05])\n",
        "    plt.xlabel('FPR')\n",
        "    plt.ylabel('TPR')\n",
        "    plt.title(Title)\n",
        "    plt.legend() \n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(12, 6)\n",
        "    \n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "    # return all the calculated vaules for use later\n",
        "    return roc_auc, fpr, tpr, thresholds"
      ],
      "metadata": {
        "id": "tKyKw4nmISif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's call this function for both classifiers:"
      ],
      "metadata": {
        "id": "5F9ps2CdcLZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the ROC curves for the neural network and the random forest and get their  \n",
        "# corresponding FPR and TPR vaules for later\n",
        "auc_NN, fpr_NN, tpr_NN, thresholds_NN = calc_roc(NN_clf, X_test_scaled, X_test_W, y_test, \"ROC curve for the neural network classifer\")\n",
        "auc_RF, fpr_RF, tpr_RF, thresholds_RF = calc_roc(RF_clf, X_test_scaled, X_test_W, y_test, \"ROC curve for the random forest classifer\")"
      ],
      "metadata": {
        "id": "FD9UhAVmcRol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that both the random forest and the neural network behave better than random classification. However, how much better than random are they? The best way to answer this question is to look at how close each of the ROC curves gets to touching the upper left corner (which represents a perfect classifier with TPR=$1$ and FPR=$0$). Although the difference is subtle, which of the two models is closer to this target, showing it is a stronger classifier?"
      ],
      "metadata": {
        "id": "fmOKNSEUIS8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.1.3: Overfitting + KS test ####"
      ],
      "metadata": {
        "id": "yLuY4wXG4jSs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As supervised machine learning involves training a classifier on example data, you can run into the problem of the model fitting 'too well' to the example data, such that it loses generality and will no longer predict unlabelled data correctly.\n",
        "\n",
        "We could also consider the case where we train our model on a smaller volume of objects than we test on. This could result in overfitting - the classifier fitting too well to this smaller data set. This makes the model too specific, so that when new objects are introduced, they are misclassified. The diagram below shows this issue:\n",
        "\n",
        "\n",
        "![overfit](https://lh6.googleusercontent.com/8L-Djt0LQTs_gRM9ZpLY4nM3nfbBp9J74osbv5EJjOngdDwu7yPSPBpUQJ_PEuXS7BE=w2400)\n",
        "\n"
      ],
      "metadata": {
        "id": "Jg1WIYO37d2S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can imagine this threshold to be akin to the difference between understanding and memorising how to solve a particular set of questions. At first, you might just get the overall idea but still incorrectly answer the majority of questions (underfitting). With more practice, you may reach a point where you are comfortable with the content and can correctly answer most of the questions (good fitting). Here is where you should stop, congratulate yourself, and move onto another fresh set of practice questions. If you keep practising even further with the same set, however, you might memorise the answers and end up not getting a grasp of their reasoning at all (overfitting)."
      ],
      "metadata": {
        "id": "2qiJSQT8eeMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certain machine learning models are susceptible to overfitting, such as decision trees, but generally, all models can struggle with this. There are many ways to overcome this:\n",
        "* Changing the test/train data ratio or increasing the volume of training data;\n",
        "* Reducing the model complexity by changing their hyperparameters:\n",
        "* * This may be reducing the maximum depth of decision trees in a random forest or increasing the number of trees;\n",
        "* * Or in a neural network this may be reducing the size of your hidden layers;\n",
        "* And generally this may be reducing the number of features in the input data which are used by the ML model. You may think of this as akin to the aphorism, **\"if you go looking for trouble, it will come\"**. More specifically, if too many data features are used, it may be possible for the model to \"spot\" patterns which are not physical, but rather an artifact of the specific data that is used.\n",
        "\n",
        "We can see if our model is overfitting be comparing the response of the $X$ test data and $X$ train data. Ideally, the response to each dataset should be the same, but if these responses are not similar, it is a sign that the classifier has underfitted or overfitted to the training data.\n",
        "\n",
        "</br>\n",
        "\n",
        "We can statistically compare these responses by using the two-sample Kolmogorov–Smirnov test, also known as a KS test. This is a “goodness of fit test” which compares two distributions and tests if they have the same distribution. We will compare the test data response to the train data response. The KS test returns a metric called the Kolmogorov–Smirnov statistic and a p-value (number describing how likely the test data would have occurred under the null hypothesis of this statistical test). The latter of the two is often easier for drawing conclusions.\n",
        "* Kolmogorov–Smirnov statistic : A metric which assesses the match or mismatch between two distributions by quantifying the distance between them. It assumes the **null hypothesis $H_0$** that they come from the same underlying distribution. Smaller values show stronger agreement.\n",
        "* P-value : the probability that $H_0$ is true; i.e. the test and train responses show the same distribution. Often, a $5\\%-95\\%$ rule is used. If the p-value is significantly greater than a $0.05$ threshold, our **$H_0$** can be accepted and the **alternative hypothesis $H_1$** can be rejected; i.e. the train and test responses show good agreement rather than severe overfitting. However, if the p-value is too close to $1.00$, we may have to double check our work as this result is suspiciously good.\n",
        "\n",
        "</br>\n",
        "\n",
        "Let’s now see if our models are overfitted. To do this, we will plot the response of the test data against the train data. Let's program a function to do just that:"
      ],
      "metadata": {
        "id": "Bs09Kp4_pHYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the needed module to preform a Kolmogorov–Smirnov test (ks test)\n",
        "from scipy.stats import ks_2samp\n",
        "\n",
        "\n",
        "def plot_overfittingCheck(clf, Title,                        \n",
        "                          sig_train, sig_train_weights, sig_test, sig_test_weights,       \n",
        "                          bkg_train, bkg_train_weights, bkg_test, bkg_test_weights,\n",
        "                          n_bins, test_size=0.33):\n",
        "    \"\"\"\n",
        "    This funtion plots the overfitting check plots, while also returning the results\n",
        "    of a Kolmogorov–Smirnov test comparing the test data response and train data response\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    \n",
        "    # get the predictions (in form of probabilities) for background and \n",
        "    # signal for the train data set and the test data set\n",
        "    sig_train_prob = clf.predict_proba(sig_train)[:, 1]\n",
        "    bkg_train_prob = clf.predict_proba(bkg_train)[:, 1]\n",
        "    \n",
        "    sig_test_prob = clf.predict_proba(sig_test)[:, 1]\n",
        "    bkg_test_prob = clf.predict_proba(bkg_test)[:, 1]\n",
        "    \n",
        "    # find min and max for plot\n",
        "    d_min = min(sig_train_prob.min(), bkg_train_prob.min())\n",
        "    d_max = max(sig_train_prob.max(), bkg_train_prob.max())\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    # plot the background response of the train data set (make orange and translucent)\n",
        "    bkg_tr, bins, _ = plt.hist(bkg_train_prob,\n",
        "                               bins=n_bins,\n",
        "                               range=(d_min,d_max), \n",
        "                               color='tab:blue', \n",
        "                               label='bkg train',\n",
        "                               alpha=0.4,\n",
        "                               weights = bkg_train_weights/(1-test_size),\n",
        "                               log = True,\n",
        "                               histtype=\"stepfilled\",\n",
        "                               edgecolor='tab:blue',\n",
        "                               linewidth=5)\n",
        "    \n",
        "    # plot the signal response of the train data set (make blue and translucent)\n",
        "    sig_tr, bins, _ = plt.hist(sig_train_prob,\n",
        "                              bins=n_bins,\n",
        "                              range=(d_min,d_max), \n",
        "                              color='tab:orange', \n",
        "                              label='sig train', \n",
        "                              alpha=0.4,\n",
        "                              weights = sig_train_weights/(1-test_size),\n",
        "                              log = True,\n",
        "                              histtype=\"stepfilled\",\n",
        "                              edgecolor='tab:orange',\n",
        "                              linewidth=5)\n",
        "    \n",
        "    \n",
        "\n",
        "    # find bin centres\n",
        "    bin_centers = (bins[:-1] + bins[1:])/2\n",
        "    # use numpy histograms to find heights of histogram bars for the test data set\n",
        "    sig_te, _ = np.histogram(sig_test_prob, bins = bins, weights = sig_test_weights/test_size)\n",
        "    bkg_te, _ = np.histogram(bkg_test_prob, bins = bins, weights = bkg_test_weights/test_size)\n",
        "    \n",
        "    # plot the test background and signal histograms as points \n",
        "    plt.plot(bin_centers,bkg_te, 'o', c = 'tab:blue', label = 'bkg test', alpha = 0.9, markeredgecolor = 'k')\n",
        "    plt.plot(bin_centers,sig_te, 'o', c = 'tab:orange', label = 'sig test', alpha = 0.9, markeredgecolor = 'k')\n",
        "    \n",
        "    # set up the plot\n",
        "    plt.title(Title)\n",
        "    plt.xlabel(\"Response (0 = background, 1 = signal)\")\n",
        "    plt.ylabel(\"Normalised frequency\")\n",
        "    plt.yscale(\"log\")\n",
        "    plt.legend()\n",
        "    \n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(12, 6)\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "    # return the Kolmogorov–Smirnov test results\n",
        "    return ks_2samp(sig_tr, sig_te)"
      ],
      "metadata": {
        "id": "e0MduVxxeQVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It may be worth highlighting that the test and training data are different sizes based on the way how the Monte Carlo data were split in Section 3. This is important since the height of a histogram bar in the training data plots would be expected to be smaller than the height of a test data histogram bar. To get around this and to allow us to make visual bin-by-bin comparisons between the test and training data, the function **rescales** both the test and training data to have the same total frequency.\n",
        "\n",
        "Let’s call this function now for the random forest:"
      ],
      "metadata": {
        "id": "PqxjnkrOc3se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preform overfitting check for both classifers and get Kolmogorov–Smirnov test results   \n",
        "ksTest_RF = plot_overfittingCheck(RF_clf, \n",
        "                                  \"Random forest overfitting check\", \n",
        "                                  sig_train, \n",
        "                                  sig_train_W,\n",
        "                                  sig_test,\n",
        "                                  sig_test_W,                                  \n",
        "                                  bkg_train, \n",
        "                                  bkg_train_W,\n",
        "                                  bkg_test, \n",
        "                                  bkg_test_W, \n",
        "                                  BINS)"
      ],
      "metadata": {
        "id": "diAkgxTgezwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ksTest_RF)"
      ],
      "metadata": {
        "id": "YRnLLp9Rptmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And the same for the neural network:"
      ],
      "metadata": {
        "id": "7ZSPPxOqe2OA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ksTest_NN = plot_overfittingCheck(NN_clf, \n",
        "                                  \"Neural network overfitting check\", \n",
        "                                  sig_train, \n",
        "                                  sig_train_W,\n",
        "                                  sig_test,\n",
        "                                  sig_test_W,                                  \n",
        "                                  bkg_train, \n",
        "                                  bkg_train_W,\n",
        "                                  bkg_test, \n",
        "                                  bkg_test_W, \n",
        "                                  BINS)"
      ],
      "metadata": {
        "id": "CkT5BzTQe4Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ksTest_NN)"
      ],
      "metadata": {
        "id": "YELL5_qyH95w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now discuss our results which do show a signficant difference between the random forest and the neural network:\n",
        "\n",
        "</br>\n",
        "\n",
        "* P-values:\n",
        "\n",
        "* * **Random forest**: The p-value for the random forest exceeds our $5-95\\%$ rule at $95.2%$. This means the KS test has determined that the test and training data responses belong to the same distribution with firm confidence. In general, a p-value like this may be a clue for us to double check that we haven't made a mistake or done anything \"dodgy\" to force good agreement. Here, we are fairly confident that we haven't done this.\n",
        "\n",
        "* * **Neural network**: The p-value for the neural network falls comfortably within the $5-95\\%$ rule at $42.6\\%$ showing relatively strong agreement between the test and train data responses, but not quite as good as fot the random forest.\n",
        "\n",
        "</br>\n",
        "\n",
        "Train vs test response graphs:\n",
        "\n",
        "* * **Random forest**: Over the majority of the response range, the normalised test and training signals visually appear to match quite well, except for the few right-most bins on the plot where the test signal response sits below the training response which is indicative of some slight overfitting.\n",
        "\n",
        "* * **Neural network**: For responses of $0.10$ or greater, the normalised test signal frequency is mostly below the training signal frequency histogram. This is indicative of clear overfitting, which is especially present in the right-most bins.\n",
        "\n"
      ],
      "metadata": {
        "id": "x1I_GvLNrA6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2: Results of the Machine Learning Method ###"
      ],
      "metadata": {
        "id": "fjUMLmlL7oQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far we have obtained and processed our data to be classified by two machine learning models - our neural network and our random forest. These have been trained on a subset of the Monte Carlo data while an independent subset has been used to test how well our trained classifiers work when faced with unlabelled data when compared with labelled data. At this point we have a few metrics which help us to evaluate the quality of our models.\n",
        "\n",
        "</br>\n",
        "\n",
        "However, now is where we begin to answer the question of how our powerful tools can be applied to the task of finding dark matter. In this section, we evaluate how well our signal is selected in and amongst background with in terms of the signal **significance**."
      ],
      "metadata": {
        "id": "oy7rpdqtfRHd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.2.1: Finding the significance ####"
      ],
      "metadata": {
        "id": "_ifaNlpOxTID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Putting all the data into a classifier means we only have one variable to optimise (the classifier response), unlike in Workbook 2 where there are many. Using the classifier output also achieves higher significance values than using individual variables because machine learning models can find complex correlations in many dimensions.\n",
        "\n",
        "We will now find the significance of the signal by doing something called a 'scan cut' on the classifier response. If we look at the response plot and imagine a vertical line on it, we can perform a cut on the response - keeping everything to the right, and using the same significance equation as we used in Workbook 2:\n",
        "\n",
        "$ \\text{significance} = \\frac{\\text{signal}}{\\sqrt{\\text{background}}} $\n",
        "\n",
        "Where “signal\" and \"background” in this equation are each the sum of all the weights of the signal or background events in the included part of the histogram (to the right of the line in the diagram below) like we did and programmed in Workbook 2.\n",
        "\n",
        "![sigcaldia](https://lh3.googleusercontent.com/Dzh5AjymVFfv7Fs8_NF27sxKfcIukVsR8DNkn3lzS49aBRvBvBQ_2EjCw_iWll8hwK4=w2400)\n",
        "\n",
        "\n",
        "We shall move this line from left to right, performing scan cutting and getting a significance value for each place we perform the cut. In turn, this can create a line plot of the significance over all of the cuts.\n",
        "\n",
        "The code to do this can be seen below (note that NumPy masks are used to select the data from the histogram, see more on this [here]( https://www.google.com/search?client=opera-gx&q=in+unison&sourceid=opera&ie=UTF-8&oe=UTF-8)):"
      ],
      "metadata": {
        "id": "bCY4C9aX7wMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run this cell before the below one\n",
        "\n",
        "def plot_response_alt(fig,clf,Title,sig,sig_weights,bkg,bkg_weights,n_bins,index,xAxis,Log):\n",
        "    \"\"\"\n",
        "    This function plots the response of a classifer on signal and background \n",
        "    Monte Carlo events\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    fig : TYPE\n",
        "        DESCRIPTION.\n",
        "    clf : TYPE\n",
        "        DESCRIPTION.\n",
        "    Title : TYPE\n",
        "        DESCRIPTION.\n",
        "    sig : TYPE\n",
        "        DESCRIPTION.\n",
        "    sig_weights : TYPE\n",
        "        DESCRIPTION.\n",
        "    bkg : TYPE\n",
        "        DESCRIPTION.\n",
        "    bkg_weights : TYPE\n",
        "        DESCRIPTION.\n",
        "    n_bins : TYPE\n",
        "        DESCRIPTION.\n",
        "    index : TYPE\n",
        "        DESCRIPTION.\n",
        "    xAxis : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    # Add this axes to the fig at index\n",
        "    ax = fig.add_subplot(index)\n",
        "    \n",
        "    \n",
        "    # Get response (in form of probabilities) of signal and background \n",
        "    sig_prob = clf.predict_proba(sig)[:, 1]\n",
        "    bkg_prob = clf.predict_proba(bkg)[:, 1]\n",
        "    # find min and max for plot\n",
        "    d_min = min(sig_prob.min(), bkg_prob.min())\n",
        "    d_max = max(sig_prob.max(), bkg_prob.max())\n",
        "    \n",
        "    \n",
        "    \n",
        "    # plot background response (make orange and translucent)\n",
        "    ax.hist(bkg_prob,\n",
        "             bins = n_bins,\n",
        "             range = (d_min,d_max),\n",
        "             color = 'tab:blue', \n",
        "             label = 'bkg test',\n",
        "             alpha = 0.4, \n",
        "             density = False,\n",
        "             weights = bkg_weights,\n",
        "             log = Log,\n",
        "             histtype=\"stepfilled\",\n",
        "             edgecolor='tab:blue',\n",
        "             linewidth=5)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    # plot signal response (make blue and translucent)\n",
        "    ax.hist(sig_prob,\n",
        "             bins = n_bins,\n",
        "             range = (d_min,d_max),\n",
        "             color = 'tab:orange', \n",
        "             label = 'sig test', \n",
        "             alpha = 0.4, \n",
        "             density = False,\n",
        "             weights = sig_weights,\n",
        "             log = Log,\n",
        "             histtype=\"stepfilled\",\n",
        "             edgecolor='tab:orange',\n",
        "             linewidth=5)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    # Set up plot\n",
        "    if Title != None:\n",
        "        ax.set_title(Title)\n",
        "    ax.set_xlabel(\"Response (0 = background, 1 = signal)\")\n",
        "    ax.set_ylabel(\"Frequency\")\n",
        "    ax.legend()\n",
        "    if not xAxis:\n",
        "        ax.xaxis.set_visible(False)\n",
        "    \n",
        "    return"
      ],
      "metadata": {
        "id": "FCqRDDPxGmWE",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define simpler equation to find the approximate median significance (approximation\n",
        "# that background count is much larger than the signal)\n",
        "def AMS_short(tpr, fpr, b_reg):\n",
        "    return tpr/np.power(fpr+b_reg, 0.5)\n",
        "\n",
        "\n",
        "# Plot significance from scan cutting\n",
        "def plot_significance(Title, \n",
        "                      clf, \n",
        "                      X_test, \n",
        "                      X_test_weight, \n",
        "                      X_test_ID,\n",
        "                      sig_test, \n",
        "                      sig_test_W,\n",
        "                      bkg_test,\n",
        "                      bkg_test_W):\n",
        "    \"\"\"\n",
        "    This function calculates the significance of the signal using the response\n",
        "    of the classifer\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    Title : TYPE\n",
        "        DESCRIPTION.\n",
        "    clf : TYPE\n",
        "        DESCRIPTION.\n",
        "    X_test : TYPE\n",
        "        DESCRIPTION.\n",
        "    X_test_weight : TYPE\n",
        "        DESCRIPTION.\n",
        "    X_test_ID : TYPE\n",
        "        DESCRIPTION.\n",
        "    sig_test : TYPE\n",
        "        DESCRIPTION.\n",
        "    sig_test_W : TYPE\n",
        "        DESCRIPTION.\n",
        "    bkg_test : TYPE\n",
        "        DESCRIPTION.\n",
        "    bkg_test_W : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    sigs : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    fig, ax = plt.subplots(2,1,sharex=True)\n",
        "    #fig.tight_layout()\n",
        "    [axi.set_axis_off() for axi in ax.ravel()]\n",
        "    # array to hold significance vaules \n",
        "    sigs = []    \n",
        "    \n",
        "    # get the predictions (in form of probabilities)\n",
        "    probs = clf.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # make an array of prediction vaules to scan over\n",
        "    prob_space = np.linspace(0,max(probs),100)\n",
        "    \n",
        "\n",
        "    #loop through prediction vaules\n",
        "    for p in prob_space:\n",
        "        \n",
        "        # generate masks to find events that correspond to the following conditions:\n",
        "        prob_mask = (probs > p)\n",
        "        sig_mask = (X_test_ID == 4.0)\n",
        "        bkg_mask = (X_test_ID != 4.0)\n",
        "        \n",
        "        # get the weights of the signal and background events that have a response\n",
        "        # less than the current cutting vaule (p from prob_space)\n",
        "        sig_weights = X_test_W[np.logical_and(prob_mask, sig_mask)]\n",
        "        bkg_weights = X_test_W[np.logical_and(prob_mask, bkg_mask)]\n",
        "        \n",
        "        # Get number of signal and number of background events that have a response\n",
        "        # less than the current cutting vaule (p from prob_space)\n",
        "        signal_selected_num = np.count_nonzero(np.logical_and(prob_mask, sig_mask))\n",
        "        background_selected_num = np.count_nonzero(np.logical_and(prob_mask, bkg_mask))\n",
        "        \n",
        "        # Find the sum of the weights found earlier\n",
        "        signal_weights_selected = np.sum(sig_weights)\n",
        "        background_weights_selected =np.sum(bkg_weights)\n",
        "        \n",
        "        # Calculate the significace, but if one of the weights sums to zero set sig to zero \n",
        "        if (background_weights_selected == 0.0 or signal_weights_selected == 0.0): # Avoid errors\n",
        "            significance = 0\n",
        "        else:\n",
        "            significance = AMS_short(signal_weights_selected, background_weights_selected,0.001) \n",
        "            \n",
        "        #append found significance vaule\n",
        "        sigs.append(significance)\n",
        "    \n",
        "    \n",
        "    # Add First plot\n",
        "    ax = fig.add_subplot(212)\n",
        "    ax.yaxis.tick_right()\n",
        "    # plot significance curve from scan cutting\n",
        "    ax.plot(prob_space, sigs)\n",
        "    \n",
        "    # Set up plot\n",
        "    ax.set_xlabel(\"Response of classifer\")\n",
        "    ax.set_ylabel(\"Significance, $\\sigma$\")\n",
        "     \n",
        "    # We will add a second plot of the reponce histogram above the significace plot \n",
        "    plot_response_alt(fig,\n",
        "                      clf, \n",
        "                      Title,               \n",
        "                      sig_test, \n",
        "                      sig_test_W,\n",
        "                      bkg_test,\n",
        "                      bkg_test_W,         \n",
        "                      BINS,\n",
        "                      211,\n",
        "                      False,\n",
        "                      True)\n",
        "    \n",
        "    # Adjust spacing of the two plots on the same figure\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    fig.set_size_inches(12, 6)\n",
        "    plt.show()\n",
        "\n",
        "    return sigs"
      ],
      "metadata": {
        "id": "26GYuc-ckNxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's call this function for the neural network:"
      ],
      "metadata": {
        "id": "i12VtQCoklrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "significance_NN = plot_significance(\"Significance from the neural network classifier\", \n",
        "                                     NN_clf, \n",
        "                                     X_test_scaled, \n",
        "                                     X_test_W, \n",
        "                                     X_test_ID,\n",
        "                                     sig_test, \n",
        "                                     sig_test_W,\n",
        "                                     bkg_test,\n",
        "                                     bkg_test_W)"
      ],
      "metadata": {
        "id": "Y0UMQ8l0k7Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And again for the random forest:"
      ],
      "metadata": {
        "id": "R3oLmhW0k6Yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "significance_FR = plot_significance(\"Significance from the random forest classifier\", \n",
        "                                     RF_clf, \n",
        "                                     X_test_scaled, \n",
        "                                     X_test_W, \n",
        "                                     X_test_ID,\n",
        "                                     sig_test, \n",
        "                                     sig_test_W,\n",
        "                                     bkg_test,\n",
        "                                     bkg_test_W)"
      ],
      "metadata": {
        "id": "3JEtwpBFk7nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s now find the highest significance for the signal (the dark matter signal) for each classifier:"
      ],
      "metadata": {
        "id": "rKz6tXM4lFpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print max significances found for each classifer\n",
        "print(\"NN significance: \",max(significance_NN),\"    With KS test results: \",ksTest_NN)\n",
        "print(\"RF significance: \",max(significance_FR),\"    With KS test results: \",ksTest_RF)"
      ],
      "metadata": {
        "id": "d5ZW1h7OlfD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, let's reassure ourselves with the following: we have now done all of the more involved work for developing and using neural networks. Hopefully everything South of this paragraph will be reusing ideas which we have already discussed in this workbook. \n",
        "\n",
        "</br>\n",
        "\n",
        "Secondly, let's now take a moment to round off our evaluation of our two models:\n",
        "\n",
        "* **Neural network:** Despite our previous comments regarding the results of our KS-test and our comparison of the test and training signal responses, we should note that the neural network looks like it can be used to obtain a sample with a DM signal significance of $2.37\\sigma$. Could $3\\sigma$ actually be reached while keeping our pesky overfitting to a minimum?\n",
        "\n",
        "* **Random forest:** Although we previously noted some reassuring results from our overfitting and response tests, the signal significance from this model is slightly lower than the neural network at $2.26\\sigma$. Given that random forests are generally \"simpler\" than neural networks, these results are not surprising (if you are surprised, feel free to look back throughout this workbook). "
      ],
      "metadata": {
        "id": "ui-qDMaLlfNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.2.2: Train your own classifier ####\n",
        "Now it is time to train your own classifier using everything you have learnt, you shouldn't have to do anything which you haven't seen before in this notebook so use this as a chance to consolidate your knowledge so far. Feel free to look back through the notebook if you are unsure on what to do."
      ],
      "metadata": {
        "id": "HGEdwfcTljE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1: Pre processing ####"
      ],
      "metadata": {
        "id": "yXO_hMWNMOuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the premade X and y datasets perform the train test split and clean up the results (remove IDs and weights for later use, see section 3.1)\n",
        "Initialise the classifier with the machine learning method of your choice (Neural Network, Random Forest or [other](https://www.google.com)) using your starting hyperparameters."
      ],
      "metadata": {
        "id": "zYdLHdtuMWwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code in in this cell "
      ],
      "metadata": {
        "id": "I43tV0_9N4-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2: Train the classifier ####"
      ],
      "metadata": {
        "id": "dZzYfkjhMd7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now train your classifer, this is a simple step where you fit the "
      ],
      "metadata": {
        "id": "zs_mbHMXMhZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code in in this cell "
      ],
      "metadata": {
        "id": "UhHSZfXKN_7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3: Analyse the classifier ####"
      ],
      "metadata": {
        "id": "SwrorxniMog5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Analyse your classifier using the prewritten functions."
      ],
      "metadata": {
        "id": "KVTiqpGyMri8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code in in this cell "
      ],
      "metadata": {
        "id": "JH4wigSMOFa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### plot_response() #####"
      ],
      "metadata": {
        "id": "u5tqTS9zK_mf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**clf** → classifier object that you trained\n",
        " \n",
        "**Title** → title of your plot\n",
        " \n",
        "**sig, sig_weights** → numpy arrays for signal events and corresponding weights\n",
        " \n",
        "**bkg, bkg_weights** → numpy arrays for background  events and corresponding weights\n",
        " \n",
        "**n_bins** → number of bins to plot histogram with\n",
        " \n",
        "**Log** → boolean to get y axis to be logarithmic or not \n"
      ],
      "metadata": {
        "id": "DERz6SokLKfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### calc_roc() #####"
      ],
      "metadata": {
        "id": "1n0SYHxbLdg_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**clf** → classifier object that you trained\n",
        " \n",
        "**X, X_weight** → premade x dataset and corresponding weights\n",
        " \n",
        "**y** →  premade y dataset\n",
        " \n",
        "**Title** → title of your plot"
      ],
      "metadata": {
        "id": "sN3u1-XfLlEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### plot_overfittingCheck() #####"
      ],
      "metadata": {
        "id": "PByfguajLvvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " \n",
        "**clf** → classifier object that you trained\n",
        " \n",
        "**Title** → title of your plot                    \n",
        " \n",
        "**sig_train, sig_train_weights, sig_test, sig_test_weights** →  numpy arrays for \n",
        "train/test signal events and corresponding weights\n",
        " \n",
        "**bkg_train, bkg_train_weights, bkg_test, bkg_test_weights** → numpy arrays for train/test background events and corresponding weights\n",
        " \n",
        "**n_bins** → number of bins to plot histogram with"
      ],
      "metadata": {
        "id": "94KHUc-ZL07m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 4: Retrain ####"
      ],
      "metadata": {
        "id": "qnvFuZEQMy9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrain your classifier if it does not meet your standards then re-analyse your classifier."
      ],
      "metadata": {
        "id": "Rzioj8V9M3oL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code in in this cell "
      ],
      "metadata": {
        "id": "pjgEBkCYOGae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 5: Calculate the significance ####"
      ],
      "metadata": {
        "id": "4GC_w_18NAoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now calculate the significance of the signal using the prewritten function"
      ],
      "metadata": {
        "id": "4spvN9MWNHDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code in in this cell "
      ],
      "metadata": {
        "id": "qA9Ew0m7OMBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### plot_significance() #####"
      ],
      "metadata": {
        "id": "9w_bGso9Ncyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Title** → title of your plot\n",
        " \n",
        "**clf** → classifier object that you trained\n",
        " \n",
        "**X_test, X_test_weight, X_test_ID** → x test dataset and corresponding weights and IDs\n",
        " \n",
        "**sig_test, sig_test_W** →   numpy arrays for test signal events and corresponding weights\n",
        " \n",
        "**bkg_test, bkg_test_W** →  numpy arrays for test background events and corresponding weights\n"
      ],
      "metadata": {
        "id": "dr6ZKXofNg3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 5 quiz ###"
      ],
      "metadata": {
        "id": "dCxp9oCzmv_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"Often when developing machine learning models, there is a trade-off between maximising the \\n\"+\n",
        "      \"TPR and minimising the FPR. If you are attempting to find a really clear signal, but are \\n\"+\n",
        "      \"confident that you have enough data to discard if need be, which of the two are you most concerned with?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Maximising TPR',1),\n",
        "                                ('Minimising FPR',0)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3rFaM9RCsiES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(f\"In principle, it is possible to perform goodness of fit tests using several different methods, \\n\"+\n",
        "      \"dependent upon the situation. One example of a test which is often used in physics is the \\nchi-squared\"+\n",
        "      \" test. Let\\'s say we wish to compare the fits in the results from two different analyses -\\n\"+\n",
        "      \"one using \"+\n",
        "      \"the chi-squared and another using the KS-test. Which metric do we want to use?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Significance',0),\n",
        "                                ('KS statistic',0), (\"The p-value\",1)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "a7BdtrgDsj2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"In one analysis (A), results are found to match a null hypothesis with a p-value of 90%. \\n\"+\n",
        "      \"In another analysis (B), results match the same hypothesis with a p-value of 10%. \\n\"+\n",
        "      \"Which experiment shows stronger agreement with the null hypothesis?\")\n",
        "out = widgets.Dropdown(options=[('',0),('A',1),\n",
        "                                ('B',0)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "L07EhPd8skFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"In the above analysis which we did, which machine learning model demonstrated stronger evidence of overfitting?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Random forest',0),\n",
        "                                ('Neural network',1)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AjDLBWr6skRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"In the same analysis, which machine learning model demonstrated evidence of finding a greater signal significance?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Random forest',0),\n",
        "                                ('Neural network',1)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "id": "jgbZqOl4skf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bH3gsz6LQ1I1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_inputs = ['lead_lep_pt', \n",
        "             'sublead_lep_pt', \n",
        "             'mll',\n",
        "             'ETmiss', \n",
        "             'dphi_pTll_ETmiss', \n",
        "             'fractional_pT_difference',\n",
        "             'ETmiss_over_HT']\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Data/data.csv\")\n",
        "data = data[data_inputs].copy()\n",
        "data = np.asarray(data)\n",
        "scaled_data = scaler.transform(data)\n",
        "\n",
        "##This cell imports all of the real data that we need in the same format as in previous MC-driven sections "
      ],
      "metadata": {
        "id": "e3i-6160i6GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are however a few differences which actually make our job quite a bit easier. Firstly we only have one file rather than several processes. This means that there is no need to combine several dataframes together. Secondly, since the data is real, it is entirely nonsensical to think about sample weights or reweighting, so we don't account for it when importing the data. Finally, we do not have to split data up between test and train datasets since all model evaluation has already been completed. \n",
        "\n",
        "However, we do still need to make sure that the data is imported with exactly the same input variables, and in a consistent manner to when the MC data were imported. Namely, we had to make sure that our numpy array for the data input, event-by-event, had the same ordering as with the MC data input. We also still have to scale our data input, since the ML models were trained and tested with normalised data inputs to help them to work.  \n",
        "\n",
        "Please take the time now to convince yourself that things are consistent between this importing of the real data and the way MC data were used in previous sections."
      ],
      "metadata": {
        "id": "TFX1JqRfkNkg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the NN and RF that you trained in Section 5.2.2 to the real data to predict if the events are signal or noise. In a similar fashion as in Section 5.1.3, we can compare the distribution of ML output when applied to the data against the distribution of ML output when applied to the test MC dataset. \n",
        "\n",
        "This allows us to assess how consistent the ML models are behaving to when they were trained and tested. Hopefully the importance of this has already been made clear to you by now; **any inconsistency now will either indicate the existence of dark matter or indicate potential improvements to our analysis to enable us to do that.** \n",
        "\n",
        "The code hidden below defines a function to plot the data's ML response against the test MC sample's (with the test sample reweighted to the larger, full dataset's size). A KS test is also performed which assesses how well the data response distribution matches the response due to the MC test **signal** sample *only*. We do this because we want to try to prove the existence of dark matter which isn't known within our current scientific understanding. Therefore, we have to consider the presence of DM as an alternate hypothesis $H_1$ against a null hypothesis $H_0$ that take as *only* background due to known Standard Model processes.\n",
        "\n",
        "Please refere back to Section 5.1.3 if you need a refresheron this before proceeding."
      ],
      "metadata": {
        "id": "WbIwsXQT8koE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run this hidden code to continue\n",
        "def plot_data(clf, Title,                        \n",
        "                          data, sig_test, sig_test_weights,\n",
        "                          bkg_test, bkg_test_weights,       \n",
        "                          n_bins, test_size=0.33, cut=None):\n",
        "    \"\"\"\n",
        "    This funtion plots the ML responses for both real data and the rescaled test dataset. \n",
        "    This rescaling ensures that the total number of events roughly matches in both cases.\n",
        "    It will also display the results\n",
        "    of a Kolmogorov–Smirnov test comparing the test data signal response and real data response.\n",
        "    This acts as a hypothesis test where H0 is SM-background-only.\n",
        "\n",
        "    Will output data, test signal and test background responses binned according to\n",
        "    the output bin centres.\n",
        "\n",
        "    A cut can also be applied as a list or 1-D array as [lower_lim, upper_lim]\n",
        "    where lower_lim and upper_lim give the intended selection cuts.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    #net_W = sum(sig_test_weights)+sum(bkg_test_weights)\n",
        "    \n",
        "    # get the predictions (in form of probabilities) for background and \n",
        "    # signal for the train data set and the test data set\n",
        "    data_prob = clf.predict_proba(data)[:, 1]\n",
        "    #bkg_train_prob = clf.predict_proba(bkg_train)[:, 1]\n",
        "    \n",
        "    sig_test_prob = clf.predict_proba(sig_test)[:, 1]\n",
        "    bkg_test_prob = clf.predict_proba(bkg_test)[:, 1]\n",
        "    \n",
        "    #Applying cuts\n",
        "    if cut:\n",
        "      data_prob = data_prob[data_prob>cut[0]]\n",
        "      data_prob = data_prob[data_prob<cut[1]]\n",
        "\n",
        "      sig_test_weights = sig_test_weights[np.logical_and(sig_test_prob>cut[0], sig_test_prob<cut[1])]\n",
        "      #sig_test_weights = sig_test_weights[sig_test_prob<cut[1]]\n",
        "      sig_test_prob = sig_test_prob[np.logical_and(sig_test_prob>cut[0], sig_test_prob<cut[1])]\n",
        "      #sig_test_prob = sig_test_prob[sig_test_prob<cut[1]]   \n",
        "\n",
        "      bkg_test_weights = bkg_test_weights[np.logical_and(bkg_test_prob>cut[0], bkg_test_prob<cut[1])]\n",
        "      #bkg_test_weights = bkg_test_weights[bkg_test_prob<cut[1]]\n",
        "      bkg_test_prob = bkg_test_prob[np.logical_and(bkg_test_prob>cut[0], bkg_test_prob<cut[1])]\n",
        "      #bkg_test_prob = bkg_test_prob[bkg_test_prob<cut[1]]      \n",
        "\n",
        "    # find min and max for plot\n",
        "    d_min = min(sig_test_prob.min(), bkg_test_prob.min(), data_prob.min())\n",
        "    d_max = max(sig_test_prob.max(), bkg_test_prob.max(), data_prob.max())\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    # plot the background response of the test data set (make orange and translucent)\n",
        "    bkg_te, bins, _ = plt.hist(bkg_test_prob,\n",
        "                               bins=n_bins,\n",
        "                               range=(d_min,d_max), \n",
        "                               color='tab:blue', \n",
        "                               label='bkg test',\n",
        "                               alpha=0.4,\n",
        "                               weights = bkg_test_weights/test_size,\n",
        "                               log = True,\n",
        "                               histtype=\"stepfilled\",\n",
        "                               edgecolor='tab:blue',\n",
        "                               linewidth=5)\n",
        "    \n",
        "    # plot the signal response of the test data set (make blue and translucent)\n",
        "    sig_te, bins, _ = plt.hist(sig_test_prob,\n",
        "                              bins=n_bins,\n",
        "                              range=(d_min,d_max), \n",
        "                              color='tab:orange', \n",
        "                              label='sig test', \n",
        "                              alpha=0.4,\n",
        "                              weights = sig_test_weights/test_size,\n",
        "                              bottom=bkg_te,\n",
        "                              stacked=True,\n",
        "                              log = True,\n",
        "                              histtype=\"stepfilled\",\n",
        "                              edgecolor='tab:orange',\n",
        "                              linewidth=5)\n",
        "    # plots shaded bars for an assumed error on the MC data of 10%\n",
        "    MCerror = 0.1*(sig_te+bkg_te)\n",
        "    plt.bar(bins[:-1], MCerror, width=bins[1]-bins[0], bottom=sig_te+bkg_te, align=\"edge\",\n",
        "            log=True,  color=\"tab:gray\", edgecolor=\"tab:gray\", linewidth=5, label=\"MC error (10%)\")\n",
        "    \n",
        "    \n",
        "\n",
        "    # find bin centres\n",
        "    bin_centers = (bins[:-1] + bins[1:])/2\n",
        "    # use numpy histograms to find heights of histogram bars for the real data set\n",
        "    data_hist, _ = np.histogram(data_prob, bins = bins)\n",
        "    #bkg_te, _ = np.histogram(bkg_test_prob, bins = bins, weights = bkg_test_weights/test_size)\n",
        "    \n",
        "    # plot the real data as points with an error bar, assumed to be equal to a standard Poisson uncertainty of sqrt(n) \n",
        "    plt.errorbar(bin_centers,data_hist, yerr=np.sqrt(data_hist), fmt='o', \n",
        "                 capsize=3, c='tab:blue', label = 'data', alpha = 0.9, markeredgecolor = 'k')\n",
        "    #plt.plot(bin_centers,sig_te, 'o', c = 'tab:orange', label = 'sig test', alpha = 0.9, markeredgecolor = 'k')\n",
        "    \n",
        "    # set up the plot\n",
        "    plt.title(Title)\n",
        "    plt.xlabel(\"Response (0 = background, 1 = signal)\")\n",
        "    plt.ylabel(\"Normalised frequency\")\n",
        "    plt.yscale(\"log\")\n",
        "    plt.legend()\n",
        "    \n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(12, 6)\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "    tot_test = bkg_te+sig_te\n",
        "\n",
        "    # return the Kolmogorov–Smirnov test results\n",
        "    #print(sum(data_hist), sum(tot_test))\n",
        "    print(ks_2samp(data_hist, bkg_te))\n",
        "    return data_hist, sig_te, bkg_te, bin_centers"
      ],
      "metadata": {
        "id": "zlW1G878sM1C",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the response for the random forest:"
      ],
      "metadata": {
        "id": "tofW5lMewEVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RF_data, RF_sig, RF_bkg, RF_bin_centers = plot_data(RF_clf, \"RF\", scaled_data, sig_test, \n",
        "                                     sig_test_W,\n",
        "                                     bkg_test,\n",
        "                                     bkg_test_W, 10, 0.33)"
      ],
      "metadata": {
        "id": "lBnUZNwzwU0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for the neural network:"
      ],
      "metadata": {
        "id": "8ZWVfWjdwIlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NN_data, NN_sig, NN_bkg, NN_bin_centers =  plot_data(NN_clf, \"NN\", scaled_data, sig_test, \n",
        "                                     sig_test_W,\n",
        "                                     bkg_test,\n",
        "                                     bkg_test_W, 10, 0.33)"
      ],
      "metadata": {
        "id": "y2b1quMaoq8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Brilliant! We have started to assess results now with **actual data**. I know, it is pretty amazing. Let's discuss the distributions and the p-values before we move on:\n",
        "\n",
        "P-values:\n",
        "\n",
        "* Random forest: When we consider the full range of RF classifier responses, the KS test gives us a **$99.4\\%$** chance that the data is identical to the background-only test response.\n",
        "\n",
        "* Neural network: Over a full range of NN responses, the KS test returns a **$78.7\\%$** probability that the data is the same as a background-only response. \n",
        "\n",
        "OK, so the obtained p-values are not looking particularly reassuring in trying to prove our $H_1$ DM hypothesis. There are two things which are worth pointing out, however, which do allow room for hope. \n",
        "\n",
        "Firstly, the KS tests in this workbook are limited by the fact that they allow the two samples in the tests to be different sizes - only the relative trends make a difference. Yet, let's look at the difference in data and test sample plots:\n",
        "\n",
        "* Random forest: Despite the test MC sample being renormalised to the same size as the data, there is shown an excess of data events above test sample's signal.\n",
        "\n",
        "* Neural network: We see a similar pattern of behaviour for the NN too. In fact, one may ask if the data excess could be explained away by the the existence of a DM signal, which the test MC plots show may contribute to this excess.\n",
        "\n",
        "Secondly, the ML models were developed as a tool to separate DM signal and SM background, to allow for a suitable enough significance by which to confirm dark matter. \n",
        "\n",
        "In the following sections, we will build on these remarks, first by applying cuts on the ML models to optimise the significance, then by considering a slightly more involved method of hypothesis testing in high-energy physics."
      ],
      "metadata": {
        "id": "V2c9OJ1UwNRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6: conclusion ##\n",
        "This workbook describes how to use machine learning to find dark matter within the ATLAS open  data project, working on supervised learning. This is when we train a machine learning model with example data of what we are looking for then the program will perform a task(find dark matter production process).\n",
        "<br>\n",
        "<br>\n",
        "We would also appreciate if you could fill out our evalutation form and quiz yourself using the link [here!](https://docs.google.com/forms/d/e/1FAIpQLSfXG7-MMOamaIhnWJT_UVmUbNjZ_INuyWto353HuNPiJQvAMQ/viewform?usp=sf_link)"
      ],
      "metadata": {
        "id": "3L_Bzt_9RE2_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QaPFBA6v6fgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7: Credits and licencing  ##\n",
        "\n",
        "Project Lead: \t\tKate Shaw\n",
        "<br>\n",
        "<br>\n",
        "Project Supervisors: \tMeirin Oan Evans, Zöe Earnshaw, Thomas Stevenson\n",
        "<br>\n",
        "<br>\n",
        "Developers: \t\tChristopher Comiskey-Erazo, Iago Rosetto, Oscar Jackson"
      ],
      "metadata": {
        "id": "jco0MPH-6f3U"
      }
    }
  ]
}